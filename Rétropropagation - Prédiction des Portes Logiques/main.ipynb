{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center;\">M2 MALIA Deep learning</div>\n",
    "# <div style=\"text-align: center;\">rendu n°1 : rétropropagation</div>\n",
    "\n",
    "\n",
    "### <div style=\"text-align: center;\">Réalisé par : </div>\n",
    "### <div style=\"text-align: center;\">GHIZLAN Moqim</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fontions d'activation et leurs dérivées ( pour la rétropropagation )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces fonctions implémentent les activations ***sigmoid***, ***relu*** et ***tanh***, utilisées dans les réseaux de neurones pour introduire de la non-linéarité et permettre au modèle de s'adapter à des données complexes.\n",
    "Les dérivées des fonctions d’activation sont calculées pour être utilisées dans l’algorithme de rétropropagation, permettant d'ajuster les poids en fonction de l'erreur obtenue en sortie.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions d'activation (pour l'entrainement)\n",
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def tanh(Z):\n",
    "    return np.tanh(Z)\n",
    "\n",
    "\n",
    "# Les dérivées des fonctions ( pour la rétrospropagation )\n",
    "def sigmoid_derivative(A):\n",
    "    return A * (1 - A)\n",
    "\n",
    "def relu_derivative(A):\n",
    "    return (A > 0).astype(float)\n",
    "\n",
    "def tanh_derivative(A):\n",
    "    return 1 - A**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation des paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction initialise les poids ***W*** et les biais ***b*** pour chaques couches. Les poids sont initialisés aléraoirement avec une faible variance ***(* 0.01)*** pour iviter une saturation des activations, alors que les biais sont initialisés à zéro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_sizes):\n",
    "    \"\"\"\n",
    "    Initialise les paramètres (poids et biais) pour un réseaux de neurones en utilisant la structur\n",
    "    spécifiée par `layer_sizes`.\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    layer_sizes : liste\n",
    "        Une liste contenant le nombre de neurones dans chaque couche du réseau, avec les couches\n",
    "        d'entrer, cachées, et de sortie.\n",
    "\n",
    "    Retourne:\n",
    "    ---------\n",
    "    parameters : dictionnaire\n",
    "        Dictionnaire contenant les matrices de poids et les vecteurs de biais pour chaque couche.\n",
    "        - \"W{l}\" : Matrice de poids pour la couche l, de dimensions (layer_sizes[l], layer_sizes[l-1]).\n",
    "        - \"b{l}\" : Vecteur de biais pour la couche l, de dimensions (layer_sizes[l], 1).\n",
    "\n",
    "    Exemple:\n",
    "    --------\n",
    "    parameters = initialize_parameters([2, 4, 1])\n",
    "    Ce code initialise un réseau avec une couche d'entrer de 2 neurones, une couche cachée de 4 neurones,\n",
    "    et une couche de sortie de 1 neurone.\n",
    "    \"\"\"\n",
    "\n",
    "    parameters = {}  # Dictionnaire pour stocker les poids et biais de chaques couches\n",
    "\n",
    "    # Boucle sur chaques couches (sauf la couche d'entrer) pour initialiser W et b\n",
    "    for l in range(1, len(layer_sizes)):\n",
    "        # Initialisations des poids avec de petit valeurs aléraoire suivant une distribaution normale\n",
    "        parameters[f\"W{l}\"] = np.random.randn(layer_sizes[l], layer_sizes[l-1]) * 0.01\n",
    "\n",
    "        # Initialisations des biais avec des zéros\n",
    "        parameters[f\"b{l}\"] = np.zeros((layer_sizes[l], 1))\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choisir la fonction d’activation en fonction des paramètres de l’utilisateur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction retourne la fonction d’activation et sa dérivée en fonction du nom passé en argument. Ca permet à l'utilisateur de configurer la fonction d'activation à utiliser pour chaques couches du réseaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_function(name):\n",
    "    \"\"\"\n",
    "    Retourne la fonction d'activation et sa dérivée en fonction du nom spécifié.\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    name : str\n",
    "        Le nom de la fonction d'activation souhaitée. Doit être l'une des valeurs suivantes:\n",
    "        - \"sigmoid\" : Fonction sigmoïde, souvent utilisée pour les sorties binaires.\n",
    "        - \"relu\" : Rectified Linear Unit (ReLU), utilisée couramment pour les couches cachées.\n",
    "        - \"tanh\" : Hyperbolic tangent (tanh), qui offre une meilleure échelle de valeurs que la sigmoïde.\n",
    "\n",
    "    Retourne:\n",
    "    ---------\n",
    "    function : callable\n",
    "        La fonction d'activation correspondant au nom donné.\n",
    "    derivative : callable\n",
    "        La fonction de dérivée associée à la fonction d'activation spécifiée.\n",
    "\n",
    "    Exceptions:\n",
    "    -----------\n",
    "    ValueError :\n",
    "        Levée si `name` ne correspond pas à une des fonctions d'activation supportées.\n",
    "\n",
    "    Exemple:\n",
    "    --------\n",
    "    activation, activation_deriv = get_activation_function(\"sigmoid\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Sélectionne et retourne la fonction d'activation et sa dérivée en fonction du nom\n",
    "    if name == \"sigmoid\":\n",
    "        return sigmoid, sigmoid_derivative\n",
    "    elif name == \"relu\":\n",
    "        return relu, relu_derivative\n",
    "    elif name == \"tanh\":\n",
    "        return tanh, tanh_derivative\n",
    "    else:\n",
    "        raise ValueError(\"Fonction d'activation no reconnue. Choisisez parmi 'sigmoid', 'relu', 'tanh'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des données pour les portes logiques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Génère les entrées et sorties pour les portes logiques ***AND***, ***OR*** et ***XOR***. Ces données servent de jeu d’entraînement pour le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_logical_gate_data(gate_type):\n",
    "    \"\"\"\n",
    "    Génère un jeu de données pour les portes logiques (AND, OR, XOR).\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    gate_type : str\n",
    "        Type de porte logique pour laquelle on cherche à générer les données.\n",
    "        Doit être 'AND', 'OR' ou 'XOR'.\n",
    "\n",
    "    Retourne:\n",
    "    ---------\n",
    "    X : np.array\n",
    "        Entrées (combinations binaires de 0 et 1) pour la porte logique.\n",
    "        Chaque ligne est un vecteur d'entrée de deux valeurs binaires.\n",
    "    Y : np.array\n",
    "        Sorties attendues de la porte logique pour chaque combinaison d'entrée.\n",
    "        Chaque ligne correspond à la sortie pour les valeurs d'entrée dans `X`.\n",
    "\n",
    "    Exceptions:\n",
    "    -----------\n",
    "    ValueError :\n",
    "        Levée si le `gate_type` n'est pas 'AND', 'OR' ou 'XOR'.\n",
    "\n",
    "    Exemple:\n",
    "    --------\n",
    "    X, Y = generate_logical_gate_data(\"AND\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Création de toutes les combinaisons d'entrées binaires pour une porte logique\n",
    "    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "    # Génération des sorties en fonction du type de porte logique\n",
    "    if gate_type == \"AND\":\n",
    "        Y = np.array([[0], [0], [0], [1]])  # AND retourne 1 seulement si les deux entrées sont 1\n",
    "    elif gate_type == \"OR\":\n",
    "        Y = np.array([[0], [1], [1], [1]])  # OR retourne 1 si au moins une entrée est 1\n",
    "    elif gate_type == \"XOR\":\n",
    "        Y = np.array([[0], [1], [1], [0]])  # XOR retourne 1 si exactement une des entrées est 1\n",
    "    elif gate_type == \"NAND\":\n",
    "        Y = np.array([[1], [1], [1], [0]])\n",
    "    elif gate_type == \"NOR\":\n",
    "        Y = np.array([[1], [0], [0], [0]])\n",
    "    else:\n",
    "        # Si le type de porte est incorrect, lever une erreur\n",
    "        raise ValueError(\"Type de porte non reconnu. Choisissez parmi: 'AND', 'OR', 'XOR', 'NAND', 'NOR'.\")\n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul du coût avec log loss pour la classification binaire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction de coût utilise ***log loss***, adaptée aux tâches de classification binaire. Elle évalue la différence entre les prédictions du modèle (***A_output***) et les valeurs réelles (***Y***).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A_output, Y):\n",
    "    \"\"\"\n",
    "    Calcule le coût d'erreur pour un réseau de neurones en utilisant l'entropie croisée binaire.\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    A_output : np.array\n",
    "        Activations de la couche de sortie (prédictions) du réseau pour chaque exemple.\n",
    "    Y : np.array\n",
    "        Sorties réelles (étiquettes) pour chaque exemple.\n",
    "\n",
    "    Retourne:\n",
    "    ---------\n",
    "    cost : float\n",
    "        Coût moyen (entropie croisée binaire) sur tous les exemples.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    m = Y.shape[0] # Nombre d'exemples\n",
    "\n",
    "    # Calcul du coût de l'entropie croisée binaire\n",
    "    # On utilise le terme +1e-8 pour éviter les erreurs de calcul dues à log(0).\n",
    "    cost = -(1 / m) * np.sum(Y * np.log(A_output + 1e-8) + (1 - Y) * np.log(1 - A_output + 1e-8))\n",
    "\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagation avant avec activation configurable pour chaque couche\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectue la propagation avant, calculant la sortie de chaque couche. Permet de spécifier des fonctions d'activation différentes pour les couches cachées et la couche de sortie, adaptant le réseau à différents types de données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, hidden_activation, output_activation):\n",
    "    \"\"\"\n",
    "    Effectue la propagation avant dans un réseau de neurones, en appliquant les activations configurables\n",
    "    pour les couches cachées et la couche de sortie.\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    X : np.array\n",
    "        Matrice d'entrée (exemples en ligne, caractéristiques en colonne).\n",
    "    parameters : dict\n",
    "        Dictionnaire contenant les poids (W) et les biais (b) de chaque couche du réseau.\n",
    "    hidden_activation : str\n",
    "        Nom de la fonction d'activation pour les couches cachées (par ex. \"relu\" ou \"tanh\").\n",
    "    output_activation : str\n",
    "        Nom de la fonction d'activation pour la couche de sortie (par ex. \"sigmoid\" pour la classification binaire).\n",
    "\n",
    "    Retourne:\n",
    "    ---------\n",
    "    A : np.array\n",
    "        Activations finales de la couche de sortie.\n",
    "    cache : dict\n",
    "        Dictionnaire contenant les activations (A) et les valeurs de pré-activation (Z) pour chaque couche,\n",
    "        utilisés pour la rétropropagation.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    cache = {\"A0\": X} # Initialisation du cache avec l'entrée initiale (couche 0)\n",
    "\n",
    "\n",
    "    L = len(parameters) // 2 # Nombre de couches dans le réseau (chaque W et b correspondent à une couche)\n",
    "\n",
    "    # Récupération des fonctions d'activation pour les couches cachées et la couche de sortie\n",
    "    hidden_activation_func, _ = get_activation_function(hidden_activation)\n",
    "    output_activation_func, _ = get_activation_function(output_activation)\n",
    "\n",
    "    # Propagation avant à travers chaque couche\n",
    "    for l in range(1, L + 1):\n",
    "\n",
    "        W, b = parameters[f\"W{l}\"], parameters[f\"b{l}\"] # Récupération des poids et des biais pour la couche actuelle\n",
    "        A_prev = cache[f\"A{l-1}\"] # Récupération de l'activation de la couche précédente\n",
    "        Z = np.dot(W, A_prev.T).T + b.T # Calcul de Z pour la couche actuelle (Z = W * A_prev + b)\n",
    "\n",
    "\n",
    "        # Application de la fonction d'activation appropriée\n",
    "        # Si c'est la dernière couche, on applique l'activation de sortie, sinon l'activation cachée\n",
    "        A = output_activation_func(Z) if l == L else hidden_activation_func(Z)\n",
    "\n",
    "        # Stockage de Z et A dans le cache pour utilisation ultérieure dans la rétropropagation\n",
    "        cache[f\"Z{l}\"], cache[f\"A{l}\"] = Z, A\n",
    "\n",
    "\n",
    "    return A, cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rétropropagation avec activation configurable pour chaque couche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectue la rétropropagation en calculant les gradients des poids et des biais. Utilise les dérivées de la fonction d’activation choisie pour chaque couche.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y, hidden_activation, output_activation):\n",
    "    \"\"\"\n",
    "    Effectue la rétropropagation pour calculer les gradients des poids et biais dans chaque couche\n",
    "    d'un réseau de neurones en utilisant des fonctions d'activation configurables.\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    parameters : dict\n",
    "        Dictionnaire contenant les poids (W) et les biais (b) pour chaque couche du réseau.\n",
    "    cache : dict\n",
    "        Dictionnaire contenant les valeurs intermédiaires (activations et Z) de chaque couche durant\n",
    "        la propagation avant, nécessaires pour la rétropropagation.\n",
    "    X : np.array\n",
    "        Les données d'entrée.\n",
    "    Y : np.array\n",
    "        Les valeurs cibles pour les données d'entrée X.\n",
    "    hidden_activation : str\n",
    "        Nom de la fonction d'activation utilisée pour les couches cachées.\n",
    "    output_activation : str\n",
    "        Nom de la fonction d'activation utilisée pour la couche de sortie.\n",
    "\n",
    "    Retourne:\n",
    "    ---------\n",
    "    gradients : dict\n",
    "        Dictionnaire contenant les gradients de chaque poids (dW) et biais (db) calculés pour la mise à jour des paramètres.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    gradients, m, L = {}, X.shape[0], len(parameters) // 2\n",
    "\n",
    "\n",
    "    # Obtenir les fonctions de dérivée pour l'activation choisie dans la couche de sortie et les couches cachées | _ parce que la fonction d'activation n'est pas utilisée dans la rétropropagation\n",
    "    _, output_activation_deriv = get_activation_function(output_activation)\n",
    "    _, hidden_activation_deriv = get_activation_function(hidden_activation)\n",
    "\n",
    "    # Récupération de l'activation finale (output) et initialisation de dA pour la rétropropagation\n",
    "    A_output = cache[f\"A{L}\"]\n",
    "    dA = - (Y / A_output) + (1 - Y) / (1 - A_output)  # Dérivée du coût par rapport à l'activation finale (log-loss)\n",
    "\n",
    "    # Parcours des couches en sens inverse pour calculer les gradients\n",
    "    for l in reversed(range(1, L + 1)):\n",
    "        A_prev = cache[f\"A{l-1}\"]  # Activation de la couche précédente\n",
    "        W = parameters[f\"W{l}\"]     # Poids de la couche actuelle\n",
    "        Z = cache[f\"Z{l}\"]          # Valeur Z de la couche actuelle\n",
    "\n",
    "        dZ = dA * output_activation_deriv(A_output) if l == L else dA * hidden_activation_deriv(Z) # Calcul du gradient dZ en fonction de la couche\n",
    "\n",
    "        # Calcul du gradient de W et b\n",
    "        dW = (1 / m) * np.dot(dZ.T, A_prev)  # Moyenne du gradient de W\n",
    "        db = (1 / m) * np.sum(dZ, axis=0, keepdims=True).T  # Moyenne du gradient de b\n",
    "\n",
    "        dA = np.dot(dZ, W) # Calcul de dA pour la couche précédente (propagation de l'erreur)\n",
    "\n",
    "        # Stocker les gradients dans le dictionnaire\n",
    "        gradients[f\"dW{l}\"] = dW\n",
    "        gradients[f\"db{l}\"] = db\n",
    "\n",
    "\n",
    "    return gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise à jour des paramètres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met à jour les paramètres ***W*** et ***b*** en utilisant les gradients calculés et le taux d’apprentissage (***learning_rate***).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, gradients, learning_rate):\n",
    "    \"\"\"\n",
    "    Met à jour les paramètres du réseau de neurones en utilisant la descente de gradient.\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    parameters : dict\n",
    "        Dictionnaire contenant les poids (W) et les biais (b) pour chaque couche du réseau.\n",
    "    gradients : dict\n",
    "        Dictionnaire contenant les gradients calculés pour chaque paramètre (dW, db) lors de la rétropropagation.\n",
    "    learning_rate : float\n",
    "        Taux d'apprentissage utilisée pour ajuster l'amplitude de la mise à jour des paramètres.\n",
    "\n",
    "    Retourne:\n",
    "    ---------\n",
    "    parameters : dict\n",
    "        Dictionnaire avec les points et les biais mis à jour pour chaques couches.\n",
    "    \"\"\"\n",
    "\n",
    "    L = len(parameters) // 2 # Calculer le nombre de couches en divisant par 2 car chaque couche a un W et un b\n",
    "    for l in range(1, L + 1):  # Boucle sur chaque couche pour mettre à jour W et b\n",
    "        parameters[f\"W{l}\"] -= learning_rate * gradients[f\"dW{l}\"]  # Mise à jour des poids W en soustrayant le produit du taux d'apprentissage et du gradient dW\n",
    "        parameters[f\"b{l}\"] -= learning_rate * gradients[f\"db{l}\"] # Mise à jour des biais b de la même manière avec le gradient db\n",
    "\n",
    "    return parameters # retourne les paramètres mis à jour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction d'entraînement avec critère d'arrêt basé sur un seuil de coût\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction d’entraînement principale. Suit l'algorithme de descente de gradient pour minimiser le coût sur un nombre spécifié d'itérations ou jusqu'à ce qu'un seuil de coût soit atteint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, Y, layer_sizes, learning_rate, iterations, cost_threshold=None, hidden_activation=\"relu\", output_activation=\"sigmoid\", print_cost=False, epochs_display=100):\n",
    "    \"\"\"\n",
    "    Entraîne le modèle de réseau de neurones en utilisant la rétropropagation et la descente de gradient,\n",
    "    avec la possibilité d'arrêter l'entraînement lorsque le coût atteint un seuil donné.\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    X : ndarray\n",
    "        Les données d'entrée, par exemple les entrées d'une porte logique (ex. [[0, 0], [0, 1], ...]).\n",
    "    Y : ndarray\n",
    "        Les valeurs cibles ou sorties attendues correspondant aux données d'entrée.\n",
    "    layer_sizes : list\n",
    "        Liste des tailles de chaque couche du réseau (entrée, couches cachées, sortie).\n",
    "    learning_rate : float\n",
    "        Taux d'apprentissage utilisé pour la mise à jour des paramètres.\n",
    "    iterations : int\n",
    "        Nombre maximal d'itérations pour l'entraînement.\n",
    "    cost_threshold : float, optionnel\n",
    "        Si spécifié, l'entraînement s'arrête lorsque le coût descend en dessous de cette valeur.\n",
    "    hidden_activation : str, optionnel\n",
    "        Fonction d'activation pour les couches cachées, par exemple 'relu', 'tanh', 'sigmoid'.\n",
    "    output_activation : str, optionnel\n",
    "        Fonction d'activation pour la couche de sortie, généralement 'sigmoid' pour la classification binaire.\n",
    "    print_cost : bool, optionnel\n",
    "        Si True, affiche le coût toutes les 100 itérations.\n",
    "    epochs_display : int, optionnel\n",
    "        Fréquence à laquelle le coût est affiché si `print_cost` est True.\n",
    "    Retourne:\n",
    "    ---------\n",
    "    parameters : dict\n",
    "        Dictionnaire contenant les paramètres entraînés du modèle (poids et biais pour chaque couche).\n",
    "    costs : list\n",
    "        Liste des valeurs de coût calculées à chaque itération, utile pour visualiser l'apprentissage.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    parameters = initialize_parameters(layer_sizes) # Génération des paramètres initiaux pour le réseaux\n",
    "    costs = [] # Initialiser une liste pour stocker le coût à chaque itération\n",
    "\n",
    "    for i in range(iterations): # Boucle principale d'entraînement pour un nombre d'itérations spécifié\n",
    "        A_output, cache = forward_propagation(X, parameters, hidden_activation, output_activation) # Étape de propagation avant pour calculer les valeurs de sortie du réseau\n",
    "        cost = compute_cost(A_output, Y) # Calcul du coût pour l'itération actuelle afin de suivre l'apprentissage\n",
    "        gradients = backward_propagation(parameters, cache, X, Y, hidden_activation, output_activation) # Rétropropagation pour calculer les gradients du coût par rapport aux paramètres\n",
    "        parameters = update_parameters(parameters, gradients, learning_rate) # Mise à jour des paramètres en utilisant les gradients et le taux d'apprentissage\n",
    "        costs.append(cost) # Enregistrer le coût dans la liste pour pouvoir suivre la courbe d'apprentissage\n",
    "        if cost_threshold and cost < cost_threshold: # Vérification du critère d'arrêt basé sur le seuil de coût\n",
    "            print(f\"Seuil de coût atteint à l'itération {i} avec un coût de {cost:.8f}\")\n",
    "            break # Arrêter l'entraînement si le seuil de coût est atteint\n",
    "        if print_cost and i % epochs_display == 0: # Option pour afficher le coût périodiquement (toutes les 100 itérations)\n",
    "            print(f\"Coût après l'itération {i}: {cost:.8f}\")\n",
    "    return parameters, costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction ***evaluate_model*** applique la propagation avant pour obtenir les valeurs de sortie puis binarise ces valeurs pour obtenir des prédictions catégoriques. Le seuil de 0.5 est utilisé pour les tâches de classification binaire (0 ou 1). Cette fonction est utile pour évaluer les performances du modèle après entraînement, en comparant les ***predictions*** et les valeurs réelles ***Y***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, Y, parameters, hidden_activation, output_activation):\n",
    "    \"\"\"\n",
    "    Évalue les performances du modèle en calculant les prédictions binaires\n",
    "    et les valeurs de sortie réelles.\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    X : ndarray\n",
    "        Les données d'entrée (par exemple, les valeurs d'entrée pour une porte logique).\n",
    "    Y : ndarray\n",
    "        Les sorties attendues pour les données d'entrée, utilisées pour évaluer la précision.\n",
    "    parameters : dict\n",
    "        Le dictionnaire contenant les paramètres du modèle (poids et biais pour chaque couche).\n",
    "    hidden_activation : str\n",
    "        La fonction d'activation utilisée pour les couches cachées, ex: 'relu', 'tanh', 'sigmoid'.\n",
    "    output_activation : str\n",
    "        La fonction d'activation utilisée pour la couche de sortie, généralement 'sigmoid' pour les tâches de classification binaire.\n",
    "\n",
    "    Retour:\n",
    "    -------\n",
    "    predictions : ndarray\n",
    "        Les prédictions binaires du modèle (0 ou 1) basées sur un seuil de 0.5.\n",
    "    A_output : ndarray\n",
    "        Les valeurs de sortie réelles du modèle avant binarisation.\n",
    "\n",
    "    Remarques:\n",
    "    ----------\n",
    "    Cette fonction utilise `forward_propagation` pour calculer les valeurs de sortie.\n",
    "    Ensuite, elle applique un seuil (0.5) pour produire des prédictions binaires, qui sont\n",
    "    renvoyées avec les sorties réelles pour comparer directement avec les valeurs attendues Y.\n",
    "    \"\"\"\n",
    "    A_output, _ = forward_propagation(X, parameters, hidden_activation, output_activation)\n",
    "    predictions = (A_output > 0.5).astype(int)  # Binariser les prédictions pour classification\n",
    "    return predictions, A_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage des courbes d'apprentissage pour les portes logiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***plot_learning_curves*** permet de suivre l'évolution du coût pour chaque porte logique à travers les itérations d'entraînement. Cette visualisation est utile pour vérifier si le modèle converge efficacement. Par exemple, une courbe de coût qui diminue régulièrement puis se stabilise indique une bonne convergence, tandis qu’une courbe fluctuante peut indiquer un problème avec les paramètres d'entraînement (trop grand ***learning_rate***, ou problème dans les données)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(costs_dict):\n",
    "    \"\"\"\n",
    "    Affiche les courbes d'apprentissage en traçant le coût en fonction des itérations\n",
    "    pour chaque cas de test (ex. portes logiques AND, OR, XOR).\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    costs_dict : dict\n",
    "        Un dictionnaire où chaque clé est le nom d'une porte logique (par exemple, 'AND')\n",
    "        et chaque valeur est une liste de coûts obtenus au cours de l'entraînement pour cette porte logique.\n",
    "\n",
    "    Remarques:\n",
    "    ----------\n",
    "    Cet fonction affichera une courbe pour chaqu'un de cas de test, qui permet de visualiser\n",
    "    la convergences de la modèle pour les différents types de portes logiques. La baise du coût\n",
    "    indique que le modèle apprend, et un coût stabilisé montre qu'il est proche de la convergence.\n",
    "    \"\"\"\n",
    "    for gate, costs in costs_dict.items():\n",
    "        plt.plot(costs, label=f\"Coût pour {gate}\")\n",
    "    plt.xlabel(\"Itérations\")\n",
    "    plt.ylabel(\"Coût\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Courbe d'apprentissage pour les portes logiques\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation du modèle avec les tests néscessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test pour la porte logique: AND\n",
      "Coût après l'itération 0: 0.69314737\n",
      "Coût après l'itération 100: 0.56233466\n",
      "Coût après l'itération 200: 0.56233394\n",
      "Coût après l'itération 300: 0.56233296\n",
      "Coût après l'itération 400: 0.56233139\n",
      "Coût après l'itération 500: 0.56232810\n",
      "Coût après l'itération 600: 0.56231922\n",
      "Coût après l'itération 700: 0.56228264\n",
      "Coût après l'itération 800: 0.56186654\n",
      "Coût après l'itération 900: 0.42114591\n",
      "Coût après l'itération 1000: 0.00431180\n",
      "Coût après l'itération 1100: 0.00143322\n",
      "Coût après l'itération 1200: 0.00079824\n",
      "Coût après l'itération 1300: 0.00053632\n",
      "Coût après l'itération 1400: 0.00039635\n",
      "Coût après l'itération 1500: 0.00031112\n",
      "Coût après l'itération 1600: 0.00025434\n",
      "Coût après l'itération 1700: 0.00021404\n",
      "Coût après l'itération 1800: 0.00018406\n",
      "Coût après l'itération 1900: 0.00016096\n",
      "Coût après l'itération 2000: 0.00014258\n",
      "Coût après l'itération 2100: 0.00012785\n",
      "Coût après l'itération 2200: 0.00011560\n",
      "Coût après l'itération 2300: 0.00010539\n",
      "Seuil de coût atteint à l'itération 2361 avec un coût de 0.00009993\n",
      "Test réussi pour AND ! Les prédictions sont correctes.\n",
      "Prédictions binaires:\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "Sorties réelles attendues:\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "\n",
      "Test pour la porte logique: OR\n",
      "Coût après l'itération 0: 0.69314813\n",
      "Coût après l'itération 100: 0.56233479\n",
      "Coût après l'itération 200: 0.56233444\n",
      "Coût après l'itération 300: 0.56233380\n",
      "Coût après l'itération 400: 0.56233244\n",
      "Coût après l'itération 500: 0.56232900\n",
      "Coût après l'itération 600: 0.56231754\n",
      "Coût après l'itération 700: 0.56225013\n",
      "Coût après l'itération 800: 0.55963015\n",
      "Coût après l'itération 900: 0.04217360\n",
      "Coût après l'itération 1000: 0.00668038\n",
      "Coût après l'itération 1100: 0.00285428\n",
      "Coût après l'itération 1200: 0.00167373\n",
      "Coût après l'itération 1300: 0.00114718\n",
      "Coût après l'itération 1400: 0.00085505\n",
      "Coût après l'itération 1500: 0.00067356\n",
      "Coût après l'itération 1600: 0.00055086\n",
      "Coût après l'itération 1700: 0.00046356\n",
      "Coût après l'itération 1800: 0.00039812\n",
      "Coût après l'itération 1900: 0.00034753\n",
      "Coût après l'itération 2000: 0.00030748\n",
      "Coût après l'itération 2100: 0.00027514\n",
      "Coût après l'itération 2200: 0.00024844\n",
      "Coût après l'itération 2300: 0.00022620\n",
      "Coût après l'itération 2400: 0.00020729\n",
      "Coût après l'itération 2500: 0.00019104\n",
      "Coût après l'itération 2600: 0.00017699\n",
      "Coût après l'itération 2700: 0.00016475\n",
      "Coût après l'itération 2800: 0.00015393\n",
      "Coût après l'itération 2900: 0.00014444\n",
      "Coût après l'itération 3000: 0.00013588\n",
      "Coût après l'itération 3100: 0.00012820\n",
      "Coût après l'itération 3200: 0.00012131\n",
      "Coût après l'itération 3300: 0.00011509\n",
      "Coût après l'itération 3400: 0.00010939\n",
      "Coût après l'itération 3500: 0.00010419\n",
      "Seuil de coût atteint à l'itération 3589 avec un coût de 0.00009998\n",
      "Test réussi pour OR ! Les prédictions sont correctes.\n",
      "Prédictions binaires:\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Sorties réelles attendues:\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      "Test pour la porte logique: XOR\n",
      "Coût après l'itération 0: 0.69314713\n",
      "Coût après l'itération 100: 0.69314680\n",
      "Coût après l'itération 200: 0.69314655\n",
      "Coût après l'itération 300: 0.69314626\n",
      "Coût après l'itération 400: 0.69314587\n",
      "Coût après l'itération 500: 0.69314527\n",
      "Coût après l'itération 600: 0.69314431\n",
      "Coût après l'itération 700: 0.69314265\n",
      "Coût après l'itération 800: 0.69313954\n",
      "Coût après l'itération 900: 0.69313379\n",
      "Coût après l'itération 1000: 0.69311742\n",
      "Coût après l'itération 1100: 0.69306163\n",
      "Coût après l'itération 1200: 0.69270855\n",
      "Coût après l'itération 1300: 0.67617415\n",
      "Coût après l'itération 1400: 0.01054084\n",
      "Coût après l'itération 1500: 0.00272544\n",
      "Coût après l'itération 1600: 0.00144240\n",
      "Coût après l'itération 1700: 0.00095179\n",
      "Coût après l'itération 1800: 0.00069998\n",
      "Coût après l'itération 1900: 0.00054735\n",
      "Coût après l'itération 2000: 0.00044671\n",
      "Coût après l'itération 2100: 0.00037559\n",
      "Coût après l'itération 2200: 0.00032295\n",
      "Coût après l'itération 2300: 0.00028241\n",
      "Coût après l'itération 2400: 0.00025028\n",
      "Coût après l'itération 2500: 0.00022445\n",
      "Coût après l'itération 2600: 0.00020311\n",
      "Coût après l'itération 2700: 0.00018531\n",
      "Coût après l'itération 2800: 0.00017016\n",
      "Coût après l'itération 2900: 0.00015718\n",
      "Coût après l'itération 3000: 0.00014593\n",
      "Coût après l'itération 3100: 0.00013606\n",
      "Coût après l'itération 3200: 0.00012739\n",
      "Coût après l'itération 3300: 0.00011968\n",
      "Coût après l'itération 3400: 0.00011283\n",
      "Coût après l'itération 3500: 0.00010663\n",
      "Coût après l'itération 3600: 0.00010107\n",
      "Seuil de coût atteint à l'itération 3621 avec un coût de 0.00009996\n",
      "Test réussi pour XOR ! Les prédictions sont correctes.\n",
      "Prédictions binaires:\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "Sorties réelles attendues:\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "\n",
      "Test pour la porte logique: NAND\n",
      "Coût après l'itération 0: 0.69314708\n",
      "Coût après l'itération 100: 0.56233497\n",
      "Coût après l'itération 200: 0.56233484\n",
      "Coût après l'itération 300: 0.56233464\n",
      "Coût après l'itération 400: 0.56233429\n",
      "Coût après l'itération 500: 0.56233367\n",
      "Coût après l'itération 600: 0.56233240\n",
      "Coût après l'itération 700: 0.56232930\n",
      "Coût après l'itération 800: 0.56231931\n",
      "Coût après l'itération 900: 0.56226479\n",
      "Coût après l'itération 1000: 0.56082757\n",
      "Coût après l'itération 1100: 0.02792571\n",
      "Coût après l'itération 1200: 0.00471050\n",
      "Coût après l'itération 1300: 0.00219444\n",
      "Coût après l'itération 1400: 0.00135540\n",
      "Coût après l'itération 1500: 0.00095710\n",
      "Coût après l'itération 1600: 0.00072884\n",
      "Coût après l'itération 1700: 0.00058308\n",
      "Coût après l'itération 1800: 0.00048251\n",
      "Coût après l'itération 1900: 0.00040951\n",
      "Coût après l'itération 2000: 0.00035451\n",
      "Coût après l'itération 2100: 0.00031159\n",
      "Coût après l'itération 2200: 0.00027723\n",
      "Coût après l'itération 2300: 0.00024931\n",
      "Coût après l'itération 2400: 0.00022609\n",
      "Coût après l'itération 2500: 0.00020660\n",
      "Coût après l'itération 2600: 0.00018992\n",
      "Coût après l'itération 2700: 0.00017556\n",
      "Coût après l'itération 2800: 0.00016308\n",
      "Coût après l'itération 2900: 0.00015219\n",
      "Coût après l'itération 3000: 0.00014250\n",
      "Coût après l'itération 3100: 0.00013395\n",
      "Coût après l'itération 3200: 0.00012625\n",
      "Coût après l'itération 3300: 0.00011936\n",
      "Coût après l'itération 3400: 0.00011313\n",
      "Coût après l'itération 3500: 0.00010747\n",
      "Coût après l'itération 3600: 0.00010229\n",
      "Seuil de coût atteint à l'itération 3648 avec un coût de 0.00009998\n",
      "Test réussi pour NAND ! Les prédictions sont correctes.\n",
      "Prédictions binaires:\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "Sorties réelles attendues:\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "\n",
      "Test pour la porte logique: NOR\n",
      "Coût après l'itération 0: 0.69314735\n",
      "Coût après l'itération 100: 0.56233488\n",
      "Coût après l'itération 200: 0.56233435\n",
      "Coût après l'itération 300: 0.56233354\n",
      "Coût après l'itération 400: 0.56233156\n",
      "Coût après l'itération 500: 0.56232724\n",
      "Coût après l'itération 600: 0.56230999\n",
      "Coût après l'itération 700: 0.56217399\n",
      "Coût après l'itération 800: 0.53521519\n",
      "Coût après l'itération 900: 0.00758514\n",
      "Coût après l'itération 1000: 0.00223883\n",
      "Coût après l'itération 1100: 0.00121730\n",
      "Coût après l'itération 1200: 0.00080620\n",
      "Coût après l'itération 1300: 0.00059402\n",
      "Coût après l'itération 1400: 0.00046486\n",
      "Coût après l'itération 1500: 0.00037989\n",
      "Coût après l'itération 1600: 0.00031891\n",
      "Coût après l'itération 1700: 0.00027401\n",
      "Coût après l'itération 1800: 0.00023962\n",
      "Coût après l'itération 1900: 0.00021225\n",
      "Coût après l'itération 2000: 0.00019025\n",
      "Coût après l'itération 2100: 0.00017199\n",
      "Coût après l'itération 2200: 0.00015678\n",
      "Coût après l'itération 2300: 0.00014387\n",
      "Coût après l'itération 2400: 0.00013280\n",
      "Coût après l'itération 2500: 0.00012325\n",
      "Coût après l'itération 2600: 0.00011483\n",
      "Coût après l'itération 2700: 0.00010744\n",
      "Coût après l'itération 2800: 0.00010093\n",
      "Seuil de coût atteint à l'itération 2815 avec un coût de 0.00009997\n",
      "Test réussi pour NOR ! Les prédictions sont correctes.\n",
      "Prédictions binaires:\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Sorties réelles attendues:\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACWBElEQVR4nOzdeVxU1fsH8M+dYWbYQWRTRAEFFSUxXCJzx1DTtCyX/IZimaWYa6b9SrMsStM0o2xxa9WvltbXElNcKnPJBXNBRQUxZRGRRWSbmfP7Y+ZeZ5wBBmbgDjPP+/VC5M6ZuefODPDwnOecwzHGGAghhBBCbIRE7A4QQgghhFgSBTeEEEIIsSkU3BBCCCHEplBwQwghhBCbQsENIYQQQmwKBTeEEEIIsSkU3BBCCCHEplBwQwghhBCbQsENIYQQQmwKBTfEot58801wHIf8/HxRz09qtmHDBnAch8zMTLG7QnQEBQVh4sSJYnfDJvXr1w/9+vVr0HPQzx/rQcFNE3b58mVMmTIFISEhcHR0hLu7O3r16oVVq1ahrKxM7O5ZjaCgILz55ptid0MU7777LrZv3y52NwgBAPz66692+71IGhcFN03UL7/8goiICPz3v//F8OHDsXr1aiQmJqJ169Z45ZVXMGPGDLG7SKxAdcHNs88+i7KyMrRp06bxO0Xs1q+//orFixeL3Y0G8/rrr9MfllbCQewOkLrLyMjA2LFj0aZNG+zduxctWrQQbps2bRouXbqEX375pVH7VFpaChcXl0Y9p60oLy+HXC6HRNJ4f2tIpVJIpdJGOx/RUCqVUKvVkMvlYnelUdnLzwcHBwc4ONCvVWtAmZsmaOnSpbhz5w7Wrl2rF9jw2rVrp5e5USqVePvtt9G2bVsoFAoEBQXhtddeQ0VFhd79OI4zmjK+vw6Ar9c4cOAApk6dCl9fX7Rq1UrvPvn5+Rg9ejTc3d3RvHlzzJgxA+Xl5QaP/c033yAqKgpOTk7w8vLC2LFjce3aNZOehz///BPdu3eHo6Mj2rZti88++8yk+xUUFGDu3LmIiIiAq6sr3N3dMWTIEJw6dUqv3f79+8FxHDZv3ozXXnsN/v7+cHFxweOPP27Qx379+qFz5844fvw4Hn74YTg5OSE4OBhr1qwx+pibNm3C66+/joCAADg7O6O4uBgAcOTIEQwePBgeHh5wdnZG3759cfDgQb3H4Mf1L126hIkTJ8LT0xMeHh6Ij4/H3bt3hXYcx6G0tBQbN24Ex3HgOE54HY3V3Bw7dgyxsbHw9vYW+j9p0iS9c2/atAlRUVFwc3ODu7s7IiIisGrVqjo/twBw9epVPP7443BxcYGvry9mzZqFXbt2geM47N+/X6+tKc+LMXV5DQFgy5YtwvvR29sb//nPf3D9+nW9NtXVbkycOBFBQUHC15mZmeA4Dh988AFWrlwpfP+dO3eu1n7rKiwsxMyZMxEYGAiFQoF27drh/fffh1qt1mtX22tjjG4fP/zwQ7Rp0wZOTk7o27cvzpw5Y9B+79696N27N1xcXODp6YkRI0YgLS1Nrw3//jx37hyeeeYZNGvWDI888ggmTpyIpKQkABDej7r1KWq1GitXrkSnTp3g6OgIPz8/TJkyBbdv39Z7fFPep6bKy8vDc889Bz8/Pzg6OqJLly7YuHGjQbtbt27h2Wefhbu7Ozw9PTFhwgScOnUKHMdhw4YNBteuq6KiArNmzYKPjw/c3Nzw+OOP499//zX4eXv/+6emxwRM+9mZnp6OUaNGwd/fH46OjmjVqhXGjh2LoqKiuj1RTRCFmE3Q//73P4SEhODhhx82qf3zzz+PjRs34qmnnsKcOXNw5MgRJCYmIi0tDdu2bat3P6ZOnQofHx8sXLgQpaWlereNHj0aQUFBSExMxOHDh/HRRx/h9u3b+Oqrr4Q277zzDt544w2MHj0azz//PG7evInVq1ejT58+OHnyJDw9Pas99+nTp/Hoo4/Cx8cHb775JpRKJRYtWgQ/P79a+33lyhVs374dTz/9NIKDg5Gbm4vPPvsMffv2xblz59CyZUu99u+88w44jsOrr76KvLw8rFy5EjExMUhNTYWTk5PQ7vbt2xg6dChGjx6NcePG4b///S9eeuklyOVygx++b7/9NuRyOebOnYuKigrI5XLs3bsXQ4YMQVRUFBYtWgSJRIL169djwIAB+OOPP9CjRw+D5zg4OBiJiYk4ceIEvvzyS/j6+uL9998HAHz99dd4/vnn0aNHD7zwwgsAgLZt2xp9TvLy8oTnc/78+fD09ERmZiZ+/PFHoc3u3bsxbtw4DBw4UDhHWloaDh48KATTpj63paWlGDBgALKzszFjxgz4+/vju+++w759+wz6VtfnxRhTXsMNGzYgPj4e3bt3R2JiInJzc7Fq1SocPHiw1vdjTdavX4/y8nK88MILUCgU8PLyMvm+d+/eRd++fXH9+nVMmTIFrVu3xl9//YUFCxYgOzsbK1euBGDaa1OTr776CiUlJZg2bRrKy8uxatUqDBgwAKdPnxa+p/bs2YMhQ4YgJCQEb775JsrKyrB69Wr06tULJ06cMPjF/PTTTyM0NBTvvvsuGGPo2rUrbty4gd27d+Prr7826MOUKVOE1+Dll19GRkYGPv74Y5w8eRIHDx6ETCYz6X1qqrKyMvTr1w+XLl1CQkICgoODsWXLFkycOBGFhYXC86ZWqzF8+HAcPXoUL730Ejp06ICffvoJEyZMMOk8zz//PL755hs888wzePjhh7F371489thjde6vLlN+dlZWViI2NhYVFRWYPn06/P39cf36dezYsQOFhYXw8PAwqw9Wj5EmpaioiAFgI0aMMKl9amoqA8Cef/55veNz585lANjevXuFYwDYokWLDB6jTZs2bMKECcLX69evZwDYI488wpRKpV7bRYsWMQDs8ccf1zs+depUBoCdOnWKMcZYZmYmk0ql7J133tFrd/r0aebg4GBw/H4jR45kjo6O7OrVq8Kxc+fOMalUymp7W5eXlzOVSqV3LCMjgykUCvbWW28Jx/bt28cAsICAAFZcXCwc/+9//8sAsFWrVgnH+vbtywCw5cuXC8cqKipYZGQk8/X1ZZWVlXqPGRISwu7evSu0VavVLDQ0lMXGxjK1Wi0cv3v3LgsODmaDBg0SjvHP8aRJk/Su4YknnmDNmzfXO+bi4qL32vH41zAjI4Mxxti2bdsYAPb3339X+7zNmDGDubu7G7zmukx9bpcvX84AsO3btwvHysrKWIcOHRgAtm/fPsZY3Z4XY0x9DSsrK5mvry/r3LkzKysrE9rt2LGDAWALFy4UjvXt25f17dvX4FwTJkxgbdq00btuAMzd3Z3l5eXV2E/e/d9rb7/9NnNxcWEXL17Uazd//nwmlUpZVlYWY8y018YYvo9OTk7s33//FY4fOXKEAWCzZs0SjvHv5Vu3bgnHTp06xSQSCYuLixOO8e/PcePGGZxv2rRpRr8///jjDwaAffvtt3rHk5OT9Y6b8j6tzv2v28qVKxkA9s033wjHKisrWXR0NHN1dRXeLz/88AMDwFauXCm0U6lUbMCAAQwAW79+vcG18/ifv1OnTtXryzPPPGPw8/b+9091j2nqz86TJ08yAGzLli21Pzk2iIalmhh++MLNzc2k9r/++isAYPbs2XrH58yZAwBm1eZMnjy52rqNadOm6X09ffp0vf78+OOPUKvVGD16NPLz84UPf39/hIaGGv0LnqdSqbBr1y6MHDkSrVu3Fo537NgRsbGxtfZboVAI9S0qlQq3bt2Cq6sr2rdvjxMnThi0j4uL03u+n3rqKbRo0UK4Fp6DgwOmTJkifC2XyzFlyhTk5eXh+PHjem0nTJigl/VJTU1Feno6nnnmGdy6dUt4PkpLSzFw4ED8/vvvBsMQL774ot7XvXv3xq1bt4T3SF3wWYkdO3agqqqq2jalpaXYvXt3tY9j6nObnJyMgIAAPP7448IxR0dHTJ48We/x6vO8GFPba3js2DHk5eVh6tSpcHR0FNo99thj6NChg1nfJ6NGjYKPj0+97rtlyxb07t0bzZo10/s+iYmJgUqlwu+//w7AtNemJiNHjkRAQIDwdY8ePdCzZ0/h+cnOzkZqaiomTpyol3l64IEHMGjQIIPvBcDw/VnbdXp4eGDQoEF61xkVFQVXV1fh54Ep71NT/frrr/D398e4ceOEYzKZDC+//DLu3LmDAwcOANC8V2Uymd57UyKRGPyMq+4cAPDyyy/rHZ85c2a9+23qz04+M7Nr1y694Wp7QcFNE+Pu7g4AKCkpMan91atXIZFI0K5dO73j/v7+8PT0xNWrV+vdl+Dg4GpvCw0N1fu6bdu2kEgkQo1Heno6GGMIDQ2Fj4+P3kdaWhry8vKqfeybN2+irKzM4BwA0L59+1r7rVar8eGHHyI0NBQKhQLe3t7w8fHBP//8Y3Qs+v7zcByHdu3aGawR07JlS4OiybCwMAAwaHv/c5eeng5AE/Tc/3x8+eWXqKioMOibbmAHAM2aNQMAgxoFU/Tt2xejRo3C4sWL4e3tjREjRmD9+vV6dVlTp05FWFgYhgwZglatWmHSpElITk7WexxTn9urV6+ibdu2BrUE979P6/O8GFPba8h/Hxh7/3To0KHBvk9qk56ejuTkZINrj4mJAQDh+8SU16Ymxr6XwsLCTHp+OnbsKAScuupy3enp6SgqKoKvr6/Btd65c0e4TlPep6a6evUqQkNDDQr5O3bsKNzOf27RogWcnZ312t3/Xq3uHBKJxGA42JSfU9Ux9WdncHAwZs+ejS+//BLe3t6IjY1FUlKSXdTbAFRz0+S4u7ujZcuWRov9amLOwlIqlcrocd3MQ13Pr1arwXEcdu7caTT74+rqWrdO1sG7776LN954A5MmTcLbb78NLy8vSCQSzJw506QsgCXc/9zx5122bBkiIyON3uf+56S6rBljrM794TgOW7duxeHDh/G///0Pu3btwqRJk7B8+XIcPnwYrq6u8PX1RWpqKnbt2oWdO3di586dWL9+PeLi4oQiTEs/t/V5Xhoax3FGn2NLfJ/cT61WY9CgQZg3b57R2/ng2ZTXprHV5brVajV8fX3x7bffGr2dz3yZ8j5tqqr7GX3/+6ouPzuXL1+OiRMn4qeffsJvv/2Gl19+WaiDvH8SiK2h4KYJGjZsGD7//HMcOnQI0dHRNbZt06YN1Go10tPThb9IACA3NxeFhYV665w0a9YMhYWFevevrKxEdnZ2nfuYnp6u95fbpUuXoFarhaLDtm3bgjGG4OBg4Qe0qXx8fODk5CT8Va/rwoULtd5/69at6N+/P9auXat3vLCwEN7e3kavRRdjDJcuXcIDDzygd/zGjRsGU14vXrwIAEZnQeji/7Jzd3cX/iq3hLoGtQ899BAeeughvPPOO/juu+8wfvx4bNq0Cc8//zwAzVDb8OHDMXz4cKjVakydOhWfffYZ3njjDbRr187k57ZNmzY4d+4cGGN6fbx06ZLe/Sz1vNT2GvLfBxcuXMCAAQP02l64cMHg++TKlSsG5zAnu1Odtm3b4s6dOyZde22vTU2MfS9dvHhReN/qPj/3O3/+PLy9vU2a6l3d+7Ft27bYs2cPevXqZVJQVNv71BRt2rTBP//8A7VarZe9OX/+vHA7/3nfvn24e/euXvbm/vdqdedQq9W4fPmyXrbG2PNo7OcvYPi+quvPzoiICEREROD111/HX3/9hV69emHNmjVYsmRJrfdtymhYqgmaN28eXFxc8PzzzyM3N9fg9suXLwtTQIcOHQoAwqwK3ooVKwBAr2q/bdu2whg+7/PPP6/2L9Ka8FM+eatXrwYADBkyBADw5JNPQiqVYvHixQZ/BTPGcOvWrWofWyqVIjY2Ftu3b0dWVpZwPC0tDbt27aq1b1Kp1OCcW7ZsMZjyy+NnkvC2bt2K7Oxs4Vp4SqVSbzp6ZWUlPvvsM/j4+CAqKqrGPkVFRaFt27b44IMPcOfOHYPbb968Wet1GePi4mL0B+b9bt++bfCc8JkSPuV//2sikUiE4IBvY+pzGxsbi+vXr+Pnn38WjpWXl+OLL77Qa2ep56W217Bbt27w9fXFmjVr9IY4du7cibS0NIPvk/Pnz+ud+9SpUyZNTa+r0aNH49ChQ0bf14WFhVAqlQBMe21qsn37dr3X6OjRozhy5Ijw/LRo0QKRkZHYuHGj3vvpzJkz+O2334SfM7XhA6D735OjR4+GSqXC22+/bXAfpVIptDflfWqqoUOHIicnB5s3b9Y71+rVq+Hq6oq+ffsC0LxXq6qq9N6barXa4GecMfzz99FHH+kdv//nMaB5XxUVFeGff/4RjmVnZxvMaDX1Z2dxcbHw/uBFRERAIpHUaxivqaHMTRPUtm1bfPfddxgzZgw6duyIuLg4dO7cGZWVlfjrr7+E6YwA0KVLF0yYMAGff/45CgsL0bdvXxw9ehQbN27EyJEj0b9/f+Fxn3/+ebz44osYNWoUBg0ahFOnTmHXrl1Gsxm1ycjIwOOPP47Bgwfj0KFDwlTILl26CNewZMkSLFiwAJmZmRg5ciTc3NyQkZGBbdu24YUXXsDcuXOrffzFixcjOTkZvXv3xtSpU4UfSp06ddL74WDMsGHD8NZbbyE+Ph4PP/wwTp8+jW+//RYhISFG23t5eeGRRx5BfHw8cnNzsXLlSrRr186g+LVly5Z4//33kZmZibCwMGzevBmpqan4/PPPIZPJauyTRCLBl19+iSFDhqBTp06Ij49HQEAArl+/jn379sHd3R3/+9//anwMY6KiorBnzx6sWLECLVu2RHBwMHr27GnQbuPGjfjkk0/wxBNPoG3btigpKcEXX3wBd3d34RfX888/j4KCAgwYMACtWrXC1atXsXr1akRGRgpZQVOf2ylTpuDjjz/GuHHjMGPGDLRo0QLffvutUMzL/4VvqeelttdQJpPh/fffR3x8PPr27Ytx48YJU8GDgoIwa9Ys4bEmTZqEFStWIDY2Fs899xzy8vKwZs0adOrUqV7F3DV55ZVX8PPPP2PYsGGYOHEioqKiUFpaitOnT2Pr1q3IzMyEt7e3Sa9NTdq1a4dHHnkEL730EioqKrBy5Uo0b95cbzhs2bJlGDJkCKKjo/Hcc88JU8E9PDxM3lKBD/JffvllxMbGQiqVYuzYsejbty+mTJmCxMREpKam4tFHH4VMJkN6ejq2bNmCVatW4amnnjLpfWqqF154AZ999hkmTpyI48ePIygoCFu3bsXBgwexcuVKoQB95MiR6NGjB+bMmYNLly6hQ4cO+Pnnn1FQUACg5uxoZGQkxo0bh08++QRFRUV4+OGHkZKSYjTrM3bsWLz66qt44okn8PLLL+Pu3bv49NNPERYWpleMb+rPzr179yIhIQFPP/00wsLCoFQq8fXXX0MqlWLUqFF1eq6apEafn0Us5uLFi2zy5MksKCiIyeVy5ubmxnr16sVWr17NysvLhXZVVVVs8eLFLDg4mMlkMhYYGMgWLFig14YxzfTGV199lXl7ezNnZ2cWGxvLLl26VO1UcGPTMflpi+fOnWNPPfUUc3NzY82aNWMJCQl6U2x5P/zwA3vkkUeYi4sLc3FxYR06dGDTpk1jFy5cqPX6Dxw4wKKiophcLmchISFszZo1BtMmjSkvL2dz5sxhLVq0YE5OTqxXr17s0KFDBlNF+WnE33//PVuwYAHz9fVlTk5O7LHHHtObgs6YZpppp06d2LFjx1h0dDRzdHRkbdq0YR9//LFeO/4xq5ueefLkSfbkk0+y5s2bM4VCwdq0acNGjx7NUlJShDb8Nd68eVPvvvdP72aMsfPnz7M+ffowJycnBkB4He9ve+LECTZu3DjWunVrplAomK+vLxs2bBg7duyY8Fhbt25ljz76KPP19WVyuZy1bt2aTZkyhWVnZ9f5uWWMsStXrrDHHnuMOTk5MR8fHzZnzhxh2u3hw4fr/LwYU5fXkDHGNm/ezLp27coUCgXz8vJi48eP15sizfvmm29YSEgIk8vlLDIyku3atavaqeDLli2rsY+67v9eY4yxkpIStmDBAtauXTsml8uZt7c3e/jhh9kHH3wgLDFgymtjjG4fly9fzgIDA5lCoWC9e/cWlm3QtWfPHtarVy/m5OTE3N3d2fDhw9m5c+f02lT3/mSMMaVSyaZPn858fHwYx3EG36uff/45i4qKYk5OTszNzY1FRESwefPmsRs3bjDGTHufVsfYezA3N5fFx8czb29vJpfLWUREhN7Ubt7NmzfZM888w9zc3JiHhwebOHEiO3jwIAPANm3aZHDtusrKytjLL7/MmjdvzlxcXNjw4cPZtWvXjC698dtvv7HOnTszuVzO2rdvz7755ptqf6bV9rPzypUrbNKkSaxt27bM0dGReXl5sf79+7M9e/bU+lzZAgpuCKlGbYGILj64Ieb58MMPGQCjAUV91OU1tEf1CcCIBr/mzp9//lmv+xsLbojlUM0NIUQU928wWF5ejs8++wyhoaF6a64QIrb736sqlQqrV6+Gu7s7HnzwQZF6RWpCNTeEEFE8+eSTaN26NSIjI1FUVIRvvvkG58+fr3Y6MCFimT59OsrKyhAdHY2Kigr8+OOP+Ouvv/Duu++aNdWfNBwKbgghooiNjcWXX36Jb7/9FiqVCuHh4di0aRPGjBkjdtcI0TNgwAAsX74cO3bsQHl5Odq1a4fVq1cjISFB7K6RanCM1WPFL0IIIYQQK0U1N4QQQgixKRTcEEIIIcSm2F3NjVqtxo0bN+Dm5mbWfkuEEEIIaTyMMZSUlKBly5YGG57ez+6Cmxs3biAwMFDsbhBCCCGkHq5du1brxp92F9zwS2pfu3YN7u7uIveGEEIIIaYoLi5GYGCg8Hu8JnYX3PBDUe7u7hTcEEIIIU2MKSUlVFBMCCGEEJtCwQ0hhBBCbAoFN4QQQgixKXZXc0MIIcQ4lUqFqqoqsbtB7JhcLq91mrcpKLghhBA7xxhDTk4OCgsLxe4KsXMSiQTBwcGQy+VmPQ4FN4QQYuf4wMbX1xfOzs60wCkRBb/IbnZ2Nlq3bm3W+9AqgpukpCQsW7YMOTk56NKlC1avXo0ePXoYbduvXz8cOHDA4PjQoUPxyy+/NHRXCSHEpqhUKiGwad68udjdIXbOx8cHN27cgFKphEwmq/fjiF5QvHnzZsyePRuLFi3CiRMn0KVLF8TGxiIvL89o+x9//BHZ2dnCx5kzZyCVSvH00083cs8JIaTp42tsnJ2dRe4JIRCGo1QqlVmPI3pws2LFCkyePBnx8fEIDw/HmjVr4OzsjHXr1hlt7+XlBX9/f+Fj9+7dcHZ2puCGEELMQENRxBpY6n0oanBTWVmJ48ePIyYmRjgmkUgQExODQ4cOmfQYa9euxdixY+Hi4tJQ3SSEEGIHbt++jcWLFyM/P1/srhAziVpzk5+fD5VKBT8/P73jfn5+OH/+fK33P3r0KM6cOYO1a9dW26aiogIVFRXC18XFxfXvMCGEEJs1a9Ys5Obm4sKFC/juu+/E7g4xg+jDUuZYu3YtIiIiqi0+BoDExER4eHgIH7QjOCGE2I6cnBxMnz4dISEhUCgUCAwMxPDhw5GSklKnx0lOTkZhYSF27tyJyspK7NixQ+/2fv36YebMmRbseeP6999/IZfL0blzZ6O3cxwHR0dHXL16Ve/4yJEjMXHiROHriRMnguM4cBwHmUwGPz8/DBo0COvWrYNarW7IS6gTUTM33t7ekEqlyM3N1Tuem5sLf3//Gu9bWlqKTZs24a233qqx3YIFCzB79mzha35XUUu7fTMHF08ehUQiRcBDXYXjHAzHD00ZUzT1fve3M3W80pT7Ge1Dfc9nSt/rec31Pl89r1l7sF73u/+c9X1/EEKAzMxM9OrVC56enli2bBkiIiJQVVWFXbt2Ydq0aSaNAPAGDx6MwYMHAwC2bt3aUF1uMJWVlTWuDbNhwwaMHj0av//+O44cOYKePXsatOE4DgsXLsTGjRtrPNfgwYOxfv16qFQq5ObmIjk5GTNmzMDWrVvx888/w8FB/InYovZALpcjKioKKSkpGDlyJADNPPeUlBQkJCTUeN8tW7agoqIC//nPf2psp1AooFAoLNXlav3+3Xf4Ny0SsoqbmHQ9tsHPR2yXXCKHwkEBR6kjFFIFHB0c4eTgBE+FJ3ydfdHZuzMifSIR4hkCCdekk6+EmGXq1KngOA5Hjx7Vq7vs1KkTJk2aJHydlZWF6dOnIyUlBRKJBIMHD8bq1auFkoiJEyeisLAQ27dvF+4zc+ZMpKamYv/+/Zg4cSIOHDiAAwcOYNWqVQCAjIwMBAUFGfQpKCgIzz33HM6dO4eff/4Znp6eeO211zBt2jSL9QfQZJI6d+4MBwcHfPPNN4iIiMC+ffuMPk+MMaxfvx6ffPIJWrVqhbVr1xoNbhISErBixQq88sor1WZ4AM3vVT4BERAQgAcffBAPPfQQBg4ciA0bNuD555+v9r6NRfTwavbs2ZgwYQK6deuGHj16YOXKlSgtLUV8fDwAIC4uDgEBAUhMTNS739q1azFy5EirWZeBE5aL5qCQaoIpxphBOwZW49fag/W6nynnI9avUl2JyspKlKDE6O0/pP8AAHCTu+GRlo9gWtdpaOPepjG7SGwcYwxlVeZNxa0vJ5nUpOxlQUEBkpOT8c477xidUOLp6QlA8wfziBEj4OrqigMHDkCpVGLatGkYM2aMECjUZtWqVbh48SI6d+4sjBb4+PhU237ZsmV47bXXsHjxYuzatQszZsxAWFgYBg0aZJH+8DZu3IiXXnoJBw8erLHdvn37cPfuXcTExCAgIAAPP/wwPvzwQ4PnrVevXrh48SLmz59vMCxXmwEDBqBLly748ccfKbgBgDFjxuDmzZtYuHAhcnJyEBkZieTkZCGCzcrKMthn4sKFC/jzzz/x22+/idFlo/yd/XANgBQcjv3nmNjdqRNTg6L72xlt08jBmrE2xphyP1Ovx5Rz1jewVTM1KlWVKFeVo0JZgQpVBcpV5bhbdReFFYX4t+RfnLp5CqfzT6OksgQ7M3did9ZuJD6SiMHBg2vtFyGmKKtSIXzhLlHOfe6tWDjLa//VdOnSJTDG0KFDhxrbpaSk4PTp08jIyBBKEr766it06tQJf//9N7p3717ruTw8PCCXy+Hs7FxryQSgCRLmz58PAAgLC8PBgwfx4YcfYtCgQRbpDy80NBRLly6ttR0/q1gqlaJz584ICQnBli1b9GppeImJiXjggQfwxx9/oHfv3ib3BQA6dOiAf/75p073aSiiBzeAJhVW3TCUsUi2ffv2Jv9SayxSB00AxprgMIHJdS1UCmI1qtRVOHfrHD5N/RQHbxzEgj8XoJljM/RsYZhqJsQWmfo7IC0tDYGBgXq1luHh4fD09ERaWlqdgglTRUdHG3y9cuVKi/cnKiqq1jaFhYX48ccf8eeffwrH/vOf/2Dt2rVGg5vw8HDExcVh/vz5tWaE7scYs5qaQasIbmwBpy2gYk17AhppImQSGbr4dMEnMZ/glQOv4Lerv+GVA68geVQynGW00iwxj5NMinNviVM76CSTmtQuNDQUHMfVqWi4OhKJxCBYEnN3dFP7Y8r6bt999x3Ky8v1amwYY1Cr1bh48SLCwsIM7rN48WKEhYXp1fyYIi0tDcHBwXW6T0Oh38QWIuGDmyaYuSFNl4ST4N3e76KVayvcrriNbZe2id0lYgM4joOz3EGUD1P/8vfy8kJsbCySkpJQWlpqcDu/w3nHjh1x7do1XLt2Tbjt3LlzKCwsRHh4OABN/Ux2drbe/VNTU/W+lsvlJm8JcPjwYYOvO3bsaNH+mGrt2rWYM2cOUlNThY9Tp06hd+/e1e4EEBgYiISEBLz22msmX/PevXtx+vRpjBo1ql79tDT6TWwhUgfNXxuMxm5II1NIFYjrFAcA+N/l/4ncG0IaT1JSElQqFXr06IEffvgB6enpSEtLw0cffSQMDcXExCAiIgLjx4/HiRMncPToUcTFxaFv377o1q0bAE0x7LFjx/DVV18hPT0dixYtwpkzZ/TOFRQUhCNHjiAzMxP5+fk1ruly8OBBLF26FBcvXkRSUhK2bNmCGTNmWLQ/pkhNTcWJEyfw/PPPo3Pnznof48aNw8aNG6FUKo3ed8GCBbhx4wb27NljcFtFRQVycnJw/fp1nDhxAu+++y5GjBiBYcOGIS4urs79bAgU3FiIRKYd4aPMDRHBoDaDwIHD2VtnkXfX+KazhNiakJAQnDhxAv3798ecOXPQuXNnoWj3008/BaDJQv30009o1qwZ+vTpg5iYGISEhGDz5s3C48TGxuKNN97AvHnz0L17d5SUlBj8kp47dy6kUinCw8Ph4+ODrKysavs1Z84cHDt2DF27dsWSJUuwYsUKxMbGWrQ/pli7di3Cw8ONFl0/8cQTyMvLw6+//mr0vl5eXnj11VdRXl5ucFtycjJatGiBoKAgDB48GPv27cNHH32En376CVKpacOKDY1j1laZ28CKi4vh4eGBoqIiuLu7W+xxzyenIGU7B6myDC9++ZjFHpcQU43/dTz+ufkP3njoDYxuP1rs7pAmory8HBkZGQgODoajo6PY3WnygoKCMHPmzCa9mrGYano/1uX3N6UZLISTaIelKHNDRPJwy4cBAKfzT4vcE0IIERf9JrYQqVym+Q8FN0QkoZ6hAIBLty+J3BNCCBEXTQW3EM1sqQqaCk5EE9ZMM6UzrSANZcoyODk4idwjQuxPZmam2F0goMyNxThoMzfMShYwIvYnyCMITg5OUDEVcktza78DIYTYKApuLESiMyylqmZqHSENzc9Zs20JzZgihNgzCm4shM/cAIBKxJUtiX3jg5vcu5S5IYTYLwpuLITffgEAlBWVIvaE2DNfZ18AlLkhhNg3Cm4sxEEuF/6vrKgQsSfEnvm50LAUIYRQcGMhDnKF8H/K3BCx8JkbGpYihNgzCm4sxMHxXs2NspKCGyIOGpYipP5u376NxYsXIz8/X+yuEDPROjcWopu5UVNwQ0RCBcWE1N+sWbOQm5uLCxcu4LvvvhO7O8QMlLmxEAdHnWGpSpotRcTBZ25uld2CUk1LEhDbl5OTg+nTpyMkJAQKhQKBgYEYPnw4UlJS6vQ4ycnJKCwsxM6dO1FZWYkdO3bo3d6vX78mu19UQUEBZs6ciTZt2kAul6Nly5aYNGmSweafEydOBMdx4DgOMpkMwcHBmDdvntHNM60dZW4sRKozW0qtVInYE2LPmjs2h5STQsVUuFV2SygwJsQWZWZmolevXvD09MSyZcsQERGBqqoq7Nq1C9OmTcP58+dNfqzBgwdj8ODBAICtW7c2VJcbTGVlJeQ6E1t4BQUFeOihhyCXy7FmzRp06tQJmZmZeP3119G9e3ccOnQIISEhQvvBgwdj/fr1qKqqwvHjxzFhwgRwHIf333+/MS/HbJS5sSCOaYIaWueGiEUqkcJD4QEAKKwoFLczhDSwqVOnguM4HD16FKNGjUJYWBg6deqE2bNn4/Dhw0K7rKwsjBgxAq6urnB3d8fo0aORm3tv6HbixIkYOXKk3mPPnDkT/fr1E24/cOAAVq1aJWQ2qttmISgoCG+//TbGjRsHFxcXBAQEICkpSa+Nuf0BNJmkhIQEzJw5E97e3oiNjTXan//7v//DjRs3sGfPHgwZMgStW7dGnz59sGvXLshkMkybNk2vvUKhgL+/PwIDAzFy5EjExMRg9+7dRh/bmlFwY0lMDQBQUc0NEZGLzAUAUKYsE7knpMliDKgsFeeDMZO6WFBQgOTkZEybNg0uLi4Gt3t6egIA1Go1RowYgYKCAhw4cAC7d+/GlStXMGbMGJOfjlWrViE6OhqTJ09GdnY2srOzERgYWG37ZcuWoUuXLjh58iTmz5+PGTNmCAGCJfrD27hxI+RyOQ4ePIg1a9YY3K5Wq7Fp0yaMHz8e/v7+erc5OTlh6tSp2LVrFwoKCow+/pkzZ/DXX38ZzQhZOxqWsiCOMTAA6kqqdSDicXZwBgDcrborck9Ik1V1F3i3pTjnfu0GIDcMVu536dIlMMbQoUOHGtulpKTg9OnTyMjIEAKSr776Cp06dcLff/+N7t2713ouDw8PyOVyODs7GwQJxvTq1Qvz588HAISFheHgwYP48MMPMWjQIIv0hxcaGoqlS5dWe/vNmzdRWFiIjh07Gr29Y8eOYIzh0qVL6NGjBwBgx44dcHV1hVKpREVFBSQSCT7++GOT+2QtKHNjQZw2c6NWUXBDxOMs0wY3SgpuiO1iJmZ40tLSEBgYqJdpCQ8Ph6enJ9LS0hqkb9HR0QZf8+eyZH+ioqJMamfqcwUA/fv3R2pqKo4cOYIJEyYgPj4eo0aNqlO/rAFlbiyIAz8sRTU3RDx85ubsrbOIaRMjcm9IkyRz1mRQxDq3CUJDQ8FxXJ2KhqsjkUgMAoAqEWsnTe2PseE4XT4+PjUGTWlpaeA4Du3atdN7TP7rdevWoUuXLli7di2ee+65ul6GqChzY0naN6NapRa5I8Se8WvclCub3vRNYiU4TjM0JMYHx5nURS8vL8TGxiIpKQmlpaUGtxcWFgLQDL1cu3YN165dE247d+4cCgsLER4eDkATBGRnZ+vdPzU1Ve9ruVwOlcq0mbC6xcz81/zQkKX6YwqJRILRo0fju+++Q05Ojt5tZWVl+OSTTxAbGwsvL69q7//aa6/h9ddfR1lZ06rho+DGgvjMjVpJw1JEPL0DegMAqtSUQSS2LSkpCSqVCj169MAPP/yA9PR0pKWl4aOPPhKGhmJiYhAREYHx48fjxIkTOHr0KOLi4tC3b19069YNADBgwAAcO3YMX331FdLT07Fo0SKcOXNG71xBQUE4cuQIMjMzkZ+fD7W6+j9iDx48iKVLl+LixYtISkrCli1bMGPGDIv2x1Tvvvsu/P39MWjQIOzcuRPXrl3D77//jtjYWFRVVRnM5Lrf008/DalUWms7a0PBjQUJNTdVtM4NEY+noycAmi1FbF9ISAhOnDiB/v37Y86cOejcubNQtPvpp58CADiOw08//YRmzZqhT58+iImJQUhICDZv3iw8TmxsLN544w3MmzcP3bt3R0lJCeLi4vTONXfuXEilUoSHh8PHx8dgATxdc+bMwbFjx9C1a1csWbIEK1asEKZqW6o/pmrevDkOHz6M/v37Y8qUKWjbti1Gjx6Ntm3b4u+//9Zb48YYBwcHJCQkYOnSpUYzZNaKY3WpNLIBxcXF8PDwQFFREdzd3S362F9O+hEVck889PAtRMU9bdHHJsRUm85vwjtH3sGgNoOwot8KsbtDrFx5eTkyMjIQHBwMR0dHsbvT5AUFBWHmzJlNdjVjsdX0fqzL72/K3FgSo2EpIj4nBycANBWcEGK/KLixoHs1NzQsRcTDTwWnYSlCiL2iqeAWxNfcMJotRUTkKNWkcim4IaTxVbctA2lclLmxIA6a8iVWRcNSRDyODprgplxFU8EJIfaJghsL4pgmqFHSIn5ERHzmpkJZIXJPCCFEHBTcWJCE3xWc9pYiIlI4KABQ5oYQYr8ouLEgDprghjbOJGJykmpmS9EKxYQQe0XBjQVJtMNSNFuKiInP3FSoKuq0YR4hhNgKCm4sSJgKTisUExHxBcUqpoJSTVlEQkx1+/ZtLF68GPn5+WJ3hZiJpoJbkDAspaSp4EQ8fEExoKm7kUllIvaGkKZj1qxZyM3NxYULF/Ddd9+J3R1iBsrcWJBECG5oKICIRyaRQcJpvrWp7obYupycHEyfPh0hISFQKBQIDAzE8OHDkZKSUqfHSU5ORmFhIXbu3InKykrs2LFD7/Z+/fo1yS0VxowZgx49eujtaF5VVYWoqCiMHz9eOPbXX39h6NChaNasGRwdHREREYEVK1YY7ITOcZzw4e7uju7du+Onn35qtOsxlejBTVJSEoKCguDo6IiePXvi6NGjNbYvLCzEtGnT0KJFCygUCoSFheHXX39tpN7WjM/c0CJ+REwcx0EhpRlTxPZlZmYiKioKe/fuxbJly3D69GkkJyejf//+mDZtWp0ea/Dgwdi+fTsAYOvWrRg2bFgD9LjhVFZWGj3+ySefICsrC++9955w7O2330Z2djY+/vhjAMC2bdvQt29ftGrVCvv27cP58+cxY8YMLFmyBGPHjjWo3Vu/fj2ys7Nx7Ngx9OrVC0899RROnz7dcBdXH0xEmzZtYnK5nK1bt46dPXuWTZ48mXl6erLc3Fyj7SsqKli3bt3Y0KFD2Z9//skyMjLY/v37WWpqqsnnLCoqYgBYUVGRpS5D8N9nl7GPp6Sw/724xOKPTUhd9NnUh3Xe0JldLLgodleIlSsrK2Pnzp1jZWVlYnelzoYMGcICAgLYnTt3DG67ffu28P+rV6+yxx9/nLm4uDA3Nzf29NNPs5ycHOH2CRMmsBEjRujdf8aMGaxv377C7QD0PjIyMoz2qU2bNuytt95iY8eOZc7Ozqxly5bs448/1mtjbn8YY6xv375s2rRpbMaMGax58+asX79+1T5PP/30E5PL5ezUqVPs77//Zg4ODuyXX35hjDF2584d1rx5c/bkk08a3O/nn39mANimTZuEYwDYtm3bhK+Li4sZALZq1apqz18XNb0f6/L7W9SamxUrVmDy5MmIj48HAKxZswa//PIL1q1bh/nz5xu0X7duHQoKCvDXX39BJtPUEQQFBTVml2skFBRTPTERGZ+5qVDRQn6k7hhjom3f4eTgBI7jam1XUFCA5ORkvPPOO3BxcTG43dPTEwCgVqsxYsQIuLq64sCBA1AqlZg2bRrGjBmD/fv3m9SnVatW4eLFi+jcuTPeeustAICPj0+17ZctW4bXXnsNixcvxq5duzBjxgyEhYVh0KBBFukPb+PGjXjppZdw8ODBGts9/vjjGDt2LOLi4lBVVYUJEyZg6NChAIDffvsNt27dwty5cw3uN3z4cISFheH777/HmDFjDG5XKpVYu3YtAEAul9ep7w1NtOCmsrISx48fx4IFC4RjEokEMTExOHTokNH7/Pzzz4iOjsa0adPw008/wcfHB8888wxeffVVSKVSo/epqKhARcW9H/DFxcWWvRAdEol2+wV17d+YhDQkfsYU7S9F6qNMWYae3/UU5dxHnjkibP5ak0uXLoExhg4dOtTYLiUlBadPn0ZGRgYCAwMBAF999RU6deqEv//+G927d6/1XB4eHpDL5XB2doa/v3+t7Xv16iX8gR4WFoaDBw/iww8/xKBBgyzSH15oaCiWLl1qUtuVK1ciICAA7u7uWLFihXD84sWLAICOHTsavV+HDh2ENrxx48ZBKpWirKwMarUaQUFBGD16tMn9bgyi1dzk5+dDpVLBz89P77ifnx9ycnKM3ufKlSvYunUrVCoVfv31V7zxxhtYvnw5lixZUu15EhMT4eHhIXzwb6aGod04k0puiMiELRgoc0NsFDNxDae0tDQEBgbq/ewPDw+Hp6cn0tLSGqRv0dHRBl/z57Jkf6Kiokxu+/3334PjOOTn5+P8+fMGt5v6fALAhx9+iNTUVOzcuRPh4eH48ssv4eXlZfL9G0OTmgquVqvh6+uLzz//HFKpFFFRUbh+/TqWLVuGRYsWGb3PggULMHv2bOHr4uLiBgtwhMwNo8wNEZeweSbNliL14OTghCPPHBHt3KYIDQ0Fx3FGf1HXlUQiMfjlXlUl3h6BpvbH2HCcMVeuXMG8efPw6aefYt++fZg4cSJOnjwpTMoBNEHXww8/bHDftLQ0hIeH6x3z9/dHu3bt0K5dO6xfvx5Dhw7FuXPn4Ovra+olNjjRMjfe3t6QSqXIzc3VO56bm1tt2q9FixYICwvTG4Lq2LEjcnJyqq0UVygUcHd31/toKNrZtxTcENHRbCliDo7j4CxzFuXDlHobAPDy8kJsbCySkpJQWlpqcHthYSEAze+Ia9eu4dq1a8Jt586dQ2FhofBL28fHB9nZ2Xr3T01N1ftaLpcbTIuuzuHDhw2+5od9LNUfU6nVakycOBEDBw5EXFwcVq5ciZKSEixcuBAA8Oijj8LLywvLly83uO/PP/+M9PR0jBs3rtrH79GjB6KiovDOO+/Uq38NRbTgRi6XIyoqSm8tArVajZSUFIOUHq9Xr164dOkS1Op74z4XL15EixYtrKKYidNmbtRq0WfYEzvHD0tR5obYsqSkJKhUKvTo0QM//PAD0tPTkZaWho8++kj4PRITE4OIiAiMHz8eJ06cwNGjRxEXF4e+ffuiW7duAIABAwbg2LFj+Oqrr5Ceno5FixbhzJkzeucKCgrCkSNHkJmZifz8fL3fQ/c7ePAgli5diosXLyIpKQlbtmzBjBkzLNofU61atQpnz57FZ599BkBTP/Tll19ixYoVOHr0KFxcXPDZZ5/hp59+wgsvvIB//vkHmZmZWLt2LSZOnIinnnqq1nqamTNn4rPPPsP169fr1ccGYZG5W/W0adMmplAo2IYNG9i5c+fYCy+8wDw9PYUpcc8++yybP3++0D4rK4u5ubmxhIQEduHCBbZjxw7m6+vLliwxfep1Q04F/99L77CPp6Swzf9ZbvHHJqQuZu2bxTpv6My+T/te7K4QK9eUp4IzxtiNGzfYtGnTWJs2bZhcLmcBAQHs8ccfZ/v27RPa1Db1mjHGFi5cyPz8/JiHhwebNWsWS0hI0Jt6feHCBfbQQw8xJyenWqeCL168mD399NPM2dmZ+fv7G0yTtkR/+vbty2bMmFHjc3PhwgXm5OTEvv32W4PbJk+ezDp27MjKy8sZY4z9/vvvLDY2lrm7uzO5XM46derEPvjgA6ZUKvXuh/umgjPGmFqtZh06dGAvvfRSjf0xhaWmgnPazorm448/xrJly5CTk4PIyEh89NFH6NlTU6Xfr18/BAUFYcOGDUL7Q4cOYdasWUhNTUVAQACee+65GmdL3a+4uBgeHh4oKiqy+BBV8uz3cflud3iVnsW4r6db9LEJqYt5v8/DzoydmNd9Hp4Nf1bs7hArVl5ejoyMDAQHB8PR0bH2O5AaBQUFYebMmU1yNWNrUNP7sS6/v0UvKE5ISEBCQoLR24zN+Y+OjjYYz7QWDk4OwF1ADfGHyIh9k0k060DRxpmEEHtExSEW5OCi3Y2ZU4jcE2Lv+OCmSi3ejA9CCBGL6JkbW6Lw0EzLU0oouCHicpBovrUpc0NI48rMzBS7CwSUubEohacbAEAloXFrIi7K3BBC7BkFNxbk3LwZAEAppeCGiEsIblQU3BBC7A8FNxbUPCwEAKCWKlB0I7eW1oQ0HGFYitGwFCHE/lBwY0FerVtBql0R9saJUyL3htgzytwQQuwZBTcWJHVwgKKqCABQcPlaLa0JaTiUuSGE2DMKbixMrtIEN3eu5YvcE2LP+MxNpcr4nmuEEGLLKLixMCfpbQBAab6oCz8TO8fvrFymLBO5J4Q0Hbdv38bixYuRn09/nDZ1FNxYmFtLzerEtxGCu4VFIveG2CsXuWbNpTtVd0TuCSFNx6xZs3D48GG8/PLLYneFmIkW8bOwbtPG4crC4yh39MZ3s3bDSZkPDmpwUAO4l83hhP8Zz/BwBsera2fsNvMe897jattwuk01X+vezsAZeWwTzs8/CGO6D2ikj/qPz0ENB1YOB1YGOSuFo6oAEq4CSokCFQ6uqJB5QiZzgMJBCoVMAncnOTydZJBIuHsn5XROaOz/eoc0X3COTnBo7gVpMy/IWwdCERoKTiar9brF4CbTrLl0p5KCG2LbcnJy8M477+CXX37B9evX4evri8jISMycORMDBw40+XGSk5NRWFiInTt34qmnnsKOHTswbNgw4fZ+/fohMjISK1eubICraDhvvvkmFi9ejClTpmDNmjXC8dTUVHTt2hUZGRkICgrSu09sbCz27NmDw4cPo3v37nq3TZw4ERs3bkRiYiLmz58vHN++fTueeOIJ8NtV7t+/H/379weg+Rnq5uaGkJAQDBo0CLNmzUKLFi0a6Io1KLixsGYBLdG+3Xacv9wGFQovVCi8xO6SXXAsy0er67+j1fV9kDC1we2FDXBOztkZ7kOHwGf6y5D5+TbAGerPVe4KgDI3xLZlZmaiV69e8PT0xLJlyxAREYGqqirs2rUL06ZNw/nz501+rMGDB2Pw4MEAgK1btzZUlxtMZWUl5HLj+xo6Ojpi7dq1mDNnDkJDQ2t8nKysLPz1119ISEjAunXrDIIb/vHef/99TJkyBc2aNavx8S5cuAB3d3cUFxfjxIkTWLp0KdauXYv9+/cjIiLC9AusIwpuGkC/BVMRfukKzm/7DeW37oCpGZhK5xeubgKD3TvAjNzOmO4BbQqFGdzVOG0DBs54O50N4ZmQnuH0jkP3OIB7m8jrplp078fpXQPTy/oY65/Bf3UO6J+DCXkqCZRwhJJzQgXnhjKuOcqdvHGp3ZMoat0BfQqXQQIVKjkF9skHIKvMEZVqNTgGSCVAn1AfdGzhZvgcMN0nFvq3Mwb13btQ3S6AMv8WKi5dgrqkBEVbf8CdvfvQ5puvoQgJqeZCG59Qc1NFNTfEdk2dOhUcx+Ho0aNwcXERjnfq1AmTJk0Svs7KysL06dORkpICiUSCwYMHY/Xq1fDz8wOgyUYUFhZi+/btwn1mzpyJ1NRU7N+/HxMnTsSBAwdw4MABrFq1CgCMZjwAza7gzz33HM6dO4eff/4Znp6eeO211zBt2jSL9QfQZJI6d+4MBwcHfPPNN4iIiMC+ffuMPk/t27eHr68v/u///g///e9/a3xO169fj2HDhuGll17CQw89hBUrVsDJyUmvTUxMDC5duoTExEQsXbq0xsfz9fWFp6cn/P39ERYWhhEjRqBr16546aWX8Oeff9Z4X3NQcNNAfNuFwPeVF8Xuhl2oqlTh4pEcHNx6CTcRjoyR3yC6dAGQexrP+p6F+oXfcepGCZL2XcKetDys54D/jopGt6D6Z9WYWo2yEyeQ8/YSVFy4gOszZyF424/gpFILXln98VPBVUwlck9IU8QYAysTJzDmnJyEoeCaFBQUIDk5Ge+8845eYMPz9PQEAKjVaowYMQKurq44cOAAlEolpk2bhjFjxgiBQm1WrVqFixcvonPnznjrrbcAAD4+PtW2X7ZsGV577TUsXrwYu3btwowZMxAWFoZBgwZZpD+8jRs34qWXXsLBgwdrbfvee++he/fuOHbsGLp162a0DWMM69evR1JSEjp06IB27dph69atePbZZ/XaSaVSvPvuu3jmmWfw8ssvo1WrVib32cnJCS+++CJmzZqFvLw8+Po2TNabghvS5MnkUnTqHQBHFxmSPz+DU3+r8ODCrVCs7QHknYUkfSe6dhyOL+K6YfZ/T2HbyeuYsSkV++b2g9yhfjX1nEQC527d0HrdWlweMhQVFy+iZPceuA+OtfDV1Y8DR8ENqT9WVoYLD0aJcu72J46Dc3autd2lS5fAGEOHDh1qbJeSkoLTp08jIyMDgYGBAICvvvoKnTp1wt9//2102OV+Hh4ekMvlcHZ2hr+/f63te/XqJdSjhIWF4eDBg/jwww8xaNAgi/SHFxoaWmvmhPfggw9i9OjRePXVV5GSkmK0zZ49e3D37l3Exmp+jv3nP//B2rVrDYIbAHjiiScQGRmJRYsWYe3atSb3GYDwmmVmZjZYcEOzpYjNCOnqg2YtXKCqUuPyRTXw4ATNDac14+ccx+HtkZ3h46bA9cIy7D5n/hYZDs2bo9m4cQCAoh3/M/vxLEUq0WSQVGoKbohtYqymMfl70tLSEBgYKAQSABAeHg5PT0+kpaU1SN+io6MNvubPZcn+REXVLQBdsmQJ/vjjD/z2229Gb1+3bh3GjBkDBwfNH0fjxo3DwYMHcfnyZaPt33//fWzcuLHO/eZfO1MydPVFmRtiMziOQ7sHffD3L6X49/xthD/6OPDXR0DGAe2MLA6uCgeM7R6I1Xsv4edT1/HYA+ZX7LsNHIBbn32Gu0f/BlOprGJoSspp+kArFJP64Jyc0P7EcdHObYrQ0FBwHFenouHqSCQSg2Cpqkq8rUtM7Y+x4biatG3bFpMnT8b8+fMNsi0FBQXYtm0bqqqq8OmnnwrHVSoV1q1bh3feecfg8fr06YPY2FgsWLAAEydONLkffDBkrGbJUihzQ2xKi3aeAICcK0VAiwcAqRwouw3czhTa9A3TjJUfv1po8l9/NXEMD4fExQXq4mJUXDL+F05jE7ZfUFNwQ+qO4zhInJ1F+TD1r3kvLy/ExsYiKSkJpaWlBrcXFhYCADp27Ihr167h2rV7W+KcO3cOhYWFCA8PB6Cpn8nOzta7f2pqqt7XcrkcKpVpmdDDhw8bfN2xY0eL9qe+Fi5ciIsXL2LTpk16x7/99lu0atUKp06dQmpqqvCxfPlybNiwodprf++99/C///0Phw4dMun8ZWVl+Pzzz9GnT58a65bMRcENsSl+Qe4AgJJb5aiolAB+nTQ3ZN/byLRzgAdkUg75dyrw723ziyY5Bwco2rUDAFRmXDH78SyBz9xQzQ2xZUlJSVCpVOjRowd++OEHpKenIy0tDR999JEwNBQTE4OIiAiMHz8eJ06cwNGjRxEXF4e+ffsKhbUDBgzAsWPH8NVXXyE9PR2LFi3CmTNn9M4VFBSEI0eOIDMzE/n5+VCrDZec4B08eBBLly7FxYsXkZSUhC1btmDGjBkW7U99+fn5Yfbs2fjoo4/0jq9duxZPPfUUOnfurPfx3HPPIT8/H8nJyUYfj7+W+x+Pl5eXh5ycHKSnp2PTpk3o1asX8vPz9bJDDYGCG2JT5E4OcPbQrPVQmFsGNNeu6XA7Q2jjKJOiU0sPAMDxq7ctc97gYABAZUZGLS0bB19zo2ZqqI2s+0OILQgJCcGJEyfQv39/zJkzB507dxaKdvlfnhzH4aeffkKzZs3Qp08fxMTEICQkBJs3bxYeJzY2Fm+88QbmzZuH7t27o6SkBHFxcXrnmjt3LqRSKcLDw+Hj44OsrKxq+zVnzhwcO3YMXbt2xZIlS7BixQqhSNdS/THH3Llz4erqKnx9/PhxnDp1CqNGjTJo6+HhgYEDB9ZYNPzWW29VG+y1b98eLVu2RFRUFN577z3ExMTgzJkzQpaqoXDMEnn5JqS4uBgeHh4oKiqCu7u72N0hDWDb8hO4kV6ImPhwtC/9Evh9GRA1ERi+Smjz1v/OYd3BDMRFt8FbIzqbfc78z7/AzRUr4P74cASYOHuhIRVVFOGRTY8AAE48e0LYSJOQ+5WXlyMjIwPBwcFwdHQUuztNXlBQEGbOnImZM2eK3ZUmqab3Y11+f1PmhtgcVy8FAKC0sALwbKM5WHhNr014S803xuWbllnBV9ayJQBAmWP+DCxL0A1maMYUIcTeUHBDbI6Luya4uVtUCbhqVvxE6U29NoHNNDMyrhVYZqEyB29vAIDSSnYT5oelAKq7IYTYH5oKTmwOX3NTWlwBuDTXHLx7S69NoJdmkbCsgrtQqRmkEvPWW3Dw1VT9K2/erKVl4+ALigGaMUVIY8rMzBS7CwSUuSE2iA9u7hZVAi7aqYalN/X2kfJzdxQCmlP/Fpp9Tj5zoy4pgbq83OzHM5ducEOZG0KIvaHghtgcR2dNvUlFmRJw1gQdUFUCFSVCG6mEg0qtCXayC80PRiSuroBE8+2kKio2+/HMxXHcvengVHNDCLEzFNwQm6PQBjeVd5WA3BmQampwUF6k125IZ80eMbdKK8w+JyeRQOqm2WlcXSJ+cAPorFJMw1KEEDtDwQ2xOQpnTSlZRZn2l7pCE3ToZm4AwNtVE/TkFZsf3ACARDs1UVVcUkvLxsEXFdMWDIQQe0PBDbE5cidNcFNZpoRazaoNblp6amZM3Si0zIwpqRDcFNXSsnEIO4PTsBQhxM5QcENsDp+5ATQBTnXBjZeLZviqsMwyG+RJ3PlhKevK3FBBMSGmuX37NhYvXox8K1nSgdQfTQUnNkfqIIGDTAJllRqVZUo4KrQrWVbo18K4O2qCmyILBTdSNz5zQzU3hDRFs2bNQm5uLi5cuIDvvvtO7O4QM1DmhtgkB4XmF3tVparazI2Hk2WDG4mTZqlwZgVTwYF7O4NT5obYspycHEyfPh0hISFQKBQIDAzE8OHDkZKSUqfHSU5ORmFhIXbu3InKykrs2LFD7/Z+/fo1yS0V3nzzTXAchxdffFHveGpqKjiOM1iXZ+PGjejevTucnZ3h5uaGvn37GjwX+/fvB8dxwoePjw+GDh2K06dPN/TlmIyCG2KTZHJt1qJCrRPc3Je50QY3xRYKbjhHTQ2PNaxzA+gEN1RzQ2xUZmYmoqKisHfvXixbtgynT59GcnIy+vfvj2nTptXpsQYPHozt27cDALZu3Yphw4Y1QI8bTmVlZbW3OTo6Yu3atUhPT6/xMebOnYspU6ZgzJgx+Oeff3D06FE88sgjGDFiBD7++GOD9hcuXEB2djZ27dqFiooKPPbYYzX2ozFRcENskl7mRqYJOlClH3S4OWp++ZeUW2bYRuJoXZkbYZ0bytwQGzV16lRwHIejR49i1KhRCAsLQ6dOnTB79mwcPnxYaJeVlYURI0bA1dUV7u7uGD16NHJz7+0DN3HiRIwcOVLvsWfOnIl+/foJtx84cACrVq0SshXVrUQcFBSEt99+G+PGjYOLiwsCAgKQlJSk18bc/gCaTFJCQgJmzpwJb29vYddxY9q3b4/+/fvj//7v/6ptc/jwYSxfvhzLli3D3Llz0a5dO3Ts2BHvvPMOZs6cidmzZ+PaNf09+nx9feHv748HH3wQM2fOxLVr13D+/Plqz9GYKLghNkkm17y1lRU6wY1Sf1aUm7bmpqxKBaVKbfY5Oe2wlLrMSoIbCdXckPphjKGqQiXKB9NZSbwmBQUFSE5OxrRp0+Di4mJwu6enJwBArVZjxIgRKCgowIEDB7B7925cuXIFY8aMMfn5WLVqFaKjozF58mRkZ2cjOzsbgYGB1bZftmwZunTpgpMnT2L+/PmYMWMGdu/ebbH+8DZu3Ai5XI6DBw9izZo1NbZ977338MMPP+DYsWNGb//+++/h6uqKKVOmGNw2Z84cVFVV4YcffjB636KiImzatAkAIJfL63gVDYMKiolNkulmbhy0i/hVk7kBgDsVSng6m/dNKRGGpSwztdxclLkh9aWsVOPzGQdEOfcLq/oK3781uXTpEhhj6NChQ43tUlJScPr0aWRkZAgByVdffYVOnTrh77//Rvfu3Ws9l4eHB+RyOZydneHv719r+169emH+/PkAgLCwMBw8eBAffvghBg0aZJH+8EJDQ7F06VKT2j744IMYPXo0Xn31VaP1SBcvXkTbtm2NBictW7aEu7s7Ll68qHe8VatWAIDS0lIAwOOPP17r69FYKHNDbJIwLFWhAhyMZ25kUgkcZZpvAUsMTQkFxVaSueFrbihzQ2yRqRmetLQ0BAYG6mVawsPD4enpibS0tAbpW3R0tMHX/Lks2Z+oqKg6tV+yZAn++OMP/Pbbb0ZvN/U55f3xxx84fvw4NmzYgLCwsFqzR43JKjI3SUlJWLZsGXJyctClSxesXr0aPXr0MNp2w4YNiI+P1zumUChQbiV1DsQ68AXFVRUqQK4JOu7P3ACAq0KG8qoKiwQ31lZQTJkbUl8OcgleWNVXtHObIjQ0FBzHWaTGQyKRGPxir6qyzESD+jC1P8aG42rStm1bTJ48GfPnz8fatWv1bgsLC8Off/6JyspKg+zNjRs3UFxcjLCwML3jwcHB8PT0RPv27ZGXl4cxY8bg999/r1OfGoromZvNmzdj9uzZWLRoEU6cOIEuXbogNjYWeXl51d7H3d1dGPfMzs7G1atXG7HHpCngMzfKSt3MjWHQ4S4UFZv/g+xe5sZKhqWo5obUE8dxkCmkonxwHGdSH728vBAbG4ukpCRhWERXYWEhAKBjx464du2aXjHsuXPnUFhYiPDwcACAj48PsrOz9e6fmpqq97VcLodKZdofCrrFzPzXHTt2tGh/6mvhwoW4ePGiUCPDGzt2LO7cuYPPPvvM4D4ffPABZDIZRo0aVe3jTps2DWfOnMG2bdss0k9ziR7crFixApMnT0Z8fDzCw8OxZs0aODs7Y926ddXeh+M4+Pv7Cx9+fn6N2GPSFDhoh5uUVWpAps3cGAluruRrfij+cjrb4La64rSzpdQVltmrylzC9guUuSE2KikpCSqVCj169MAPP/yA9PR0pKWl4aOPPhKGhmJiYhAREYHx48fjxIkTOHr0KOLi4tC3b19069YNADBgwAAcO3YMX331FdLT07Fo0SKcOXNG71xBQUE4cuQIMjMzkZ+fD7W6+kkIBw8exNKlS3Hx4kUkJSVhy5YtmDFjhkX7U19+fn6YPXs2PvroI73j0dHRmDFjBl555RUsX74cly9fxvnz5/H6669j1apVWL58eY1F1M7Ozpg8eTIWLVpU5+GthiBqcFNZWYnjx48jJiZGOCaRSBATE4NDhw5Ve787d+6gTZs2CAwMxIgRI3D27NnG6C5pQqRSzVtbrWSAAz8sVX1G5atD5mf/hKngVpa5oXVuiK0KCQnBiRMn0L9/f8yZMwedO3cWinY//fRTAJo/hn/66Sc0a9YMffr0QUxMDEJCQrB582bhcWJjY/HGG29g3rx56N69O0pKShAXF6d3rrlz50IqlSI8PBw+Pj7Iysqqtl9z5szBsWPH0LVrVyxZsgQrVqwQpmpbqj/mmDt3LlxdXQ2Or1y5Ep988gm+//57dO7cGd26dcPvv/+O7du3Y/r06bU+bkJCAtLS0rBlyxaL9bW+OCZiiHXjxg0EBATgr7/+0ivAmjdvHg4cOIAjR44Y3OfQoUNIT0/HAw88gKKiInzwwQf4/fffcfbsWaFyW1dFRQUqdP6SLi4uRmBgIIqKiuCu3eiQ2J5D2y7hxK4sdBkYiEfCzwJbJgCto4FJyXrtot7ejVullRj2QAt8/MyDZp2z9OhRZMVNgDwkBG1//cWsx7KEF357AYeyDyGxdyKGhTStBclI4ykvL0dGRgaCg4PhqA3QSf0FBQVh5syZTXI1Y2tQ0/uxuLgYHh4eJv3+Fn1Yqq6io6MRFxeHyMhI9O3bFz/++CN8fHyMjhMCQGJiIjw8PISPmtJqxHZItJkblVKts86N4bDUU900AbG/u/k/1CVOVjYVnDI3hBA7JWpw4+3tDalUqrcyIwDk5uaatJYAAMhkMnTt2hWXLl0yevuCBQtQVFQkfNy/wiKxTVIHflhKrTMsVf0splP/Fpp9Tk6hWU+HlVtHzY1CqulPuZGgjhBCbJmowY1cLkdUVJTegkJqtRopKSkG6wRUR6VS4fTp02jRooXR2xUKBdzd3fU+iO3jgxuVklW7QjEArP0jAwDwd+Zts88p0U6fZCJOIdXlLte814sqi0TuCSH2IzMzk4akrIDo69zMnj0bEyZMQLdu3dCjRw+sXLkSpaWlwlo2cXFxCAgIQGJiIgDgrbfewkMPPYR27dqhsLAQy5Ytw9WrV/H888+LeRnEykgcNNNJVSp1tSsUA4BSbbmSM06m2c6BWcnGcY7ajFWFyjoySYQQ0lhED27GjBmDmzdvYuHChcjJyUFkZCSSk5OF6d1ZWVmQSO4lmG7fvo3JkycjJycHzZo1Q1RUFP766y9hfQBCAJ3MTZW62hWKAeClfm3x6f7LFjknx2duKivBGDN5vY6Gwi/ip2bm75tFCCFNiejBDaCZPpaQkGD0tv379+t9/eGHH+LDDz9shF6RpkyqzdyoVQxw0K62qTTMqPQM9sKn+y+jc4D5w5V85gaMASoV4CDutxcfXFFwQ0xR07othDQWS03gtorghhBLu1dzowYk2qBDbVgL46DNCp65Xmz2OTmdJctZZSU4kYMbytwQU8jlckgkEty4cQM+Pj6Qy+WiZx2JfWKM4ebNm5oVsvk/FuuJghtik/SCG6k26FArNVkVnR/cGbfuLdtu7lASp/PNaA1FxRJO+xzQCsWkBhKJBMHBwcjOzsaNGzfE7g6xcxzHoVWrVpBKa98ZviYU3BCbJNGdLSXVeZurlYD0XhBSWnFv3yWVmsFBasZfrA4OmsCJMasoKqbMDTGVXC5H69atoVQqTd4/iZCGIJPJzA5sAApuiI3ia270hqUAQFWlF9x08HcT/q9UMziY8T3FcRw4mUxTUGxNmRtaxI+YgB8KMHc4gBBr0ORWKCbEFPf2llLrBTP31930DG4u/F9lgWnhujOmxEaZG0KIvaLghtgkqcxIQbHmgH47yb1hKEuseSOsdWNNmRuquSGE2BkKbohN0luhWCIBtL/o78/cOOgGNyrzMxx85kZtBZkbPrhhEG1vXEIIEQUFN8QmSaT8OjfagIXP3qj0gxuJTnCTcj7P7PMKM6asKXNDNTeEEDtDwQ2xSXorFAP36m5U1WdULuSUmH1ea8rcUM0NIcReUXBDbNK9vaUYf0DzWa2s5h5AeAvLrVJMNTeEECIeCm6ITdJbxA/QydwYBh1dAj0BAAqZ+d8OVjVbSkKZG0KIfaLghtgkvuYGDGBqVuMWDB5OmtsqqixXUEyZG0IIEQ8FN8Qm6RYKq5nOKsUqw2EphTbLU6G0QHDDD0tVih/cUM0NIcReUXBDbBKnE9wwFdPZX8ow6LgX3Jif4eDk1lNzQ7uCE0LsFQU3xCZJdPaIUqtYtVPBAUBu0cyNFdXcUOaGEGKnKLghNklvWEqtMyxlNHOjCQLKqyyQuXHQnIcpxc/cUM0NIcReUXBDbJLusJR+5qb6mptKS2RutMENlNVPOW8slLkhhNgrCm6ITeI4TsjeMDWrcRE/fgq4RYalhMyN+MENZW4IIfaKghtiszh+C4ZapoLzw1KWKCiGTBvcWEFBMWVuCCH2ioIbYrP4zI1aZdpUcEsOS7EqK8rc0N5ShBA7Q8ENsVl6m2fWmLmx5LCUdiq4FQ1L0a7ghBB7Q8ENsVl8UbFar+bGSHAj0w5LWWKFYpotRQghoqPghtgsPnOj2X6h+o0zLbqIn3aFYquaLaWmmhtCiH2h4IbYLP2amxoyN9rgptwSmRuZFdbcUOaGEGJnKLghNkti4mwpV4UmICmttEBAYkVTwWm2FCHEXlFwQ2wWX3PDasncuGiDmzvl5gckVlVQLKHMDSHEPlFwQ2yWqcNS/N5SlSrbKiimzA0hxF5RcENslqnDUg66s6rMZE3bL3CgXcEJIfaJghtisyRSzdu7tqngEk4TBCgtEdxYUUGxVEKZG0KIfaLghtgsvZqbGqaCO/AZHmaBxe6sqKCYZksRQuwVBTfEZklMXMSPH5bKv2O4qWZdWVNBsVwiBwBUGblmQgixZRTcEJt1b/uFmmtu+GEpACguNy8QsKaCYmeZMwCgTFkmck8IIaRxUXBDbNa97RfUNW6cqRvcZN26a945tTU3sIKaGycHJwBAqbJU5J4QQkjjouCG2Cxh+4VaMjdVOlPA+dWK64uzopobmfaa1UxNRcWEELtCwQ2xWXpTwWuouVHpFBLLzQxurLGgGKAZU4QQ+0LBDbFZeov41TBbKszXzWLntKaCYgpuCCH2ioIbYrP44IbpZm6MBDcSCQc37RYM5i51Y00FxfwKxQAFN4QQ+0LBDbFZnHZYSqVbc1PNtOiSCk3Qc+LqbfPOaUUFxZxOoTQFN4QQe2IVwU1SUhKCgoLg6OiInj174ujRoybdb9OmTeA4DiNHjmzYDpImyXjmpuaMyqqUdLPOaU0FxZS5IYTYK9GDm82bN2P27NlYtGgRTpw4gS5duiA2NhZ5eXk13i8zMxNz585F7969G6mnpKnRX+em+qnguhjMHJfig5sq8YeldDM3tEoxIcSeiB7crFixApMnT0Z8fDzCw8OxZs0aODs7Y926ddXeR6VSYfz48Vi8eDFCQkIasbekKTG6QnEtmRtzWVNBMWVuCCH2StTgprKyEsePH0dMTIxwTCKRICYmBocOHar2fm+99RZ8fX3x3HPP1XqOiooKFBcX630Q+8BpN85k6tprbnjmbi8lbJxpBcENvys4QMENIcS+iBrc5OfnQ6VSwc/PT++4n58fcnJyjN7nzz//xNq1a/HFF1+YdI7ExER4eHgIH4GBgWb3mzQNelPB+RWKGzpzI7OezA3HccJ0cApuCCH2RPRhqbooKSnBs88+iy+++ALe3t4m3WfBggUoKioSPq5du9bAvSTWQn+dG35YqmFrT/iCYlhBzQ0ASEDBDSHE/jiIeXJvb29IpVLk5ubqHc/NzYW/v79B+8uXLyMzMxPDhw8XjqnVmh/aDg4OuHDhAtq2bat3H4VCAYVC0QC9J9aO012huIZF/Cx6TiuaLQVoF/JjFNwQQuyLqJkbuVyOqKgopKSkCMfUajVSUlIQHR1t0L5Dhw44ffo0UlNThY/HH38c/fv3R2pqKg05ET36e0vxs6UatuaGny0FxsBU4s9Qkko0RcVqUHBDCLEfomZuAGD27NmYMGECunXrhh49emDlypUoLS1FfHw8ACAuLg4BAQFITEyEo6MjOnfurHd/T09PADA4Toj+bCk+c9PAw1LamhtAk73hpNIaWjc8vqiYz3ASQog9ED24GTNmDG7evImFCxciJycHkZGRSE5OFoqMs7KyIJE0qdIgYiUk9RiW8nYzbwhTqLkBwKqUgMhDovx0cMrcEELsiejBDQAkJCQgISHB6G379++v8b4bNmywfIeITeD4FYpVap3gpuZhqRFdWpp3Tp3gBlawvxS/kB8t4kcIsSeUEiE2y/hsKeOZG19txib5rPElCEymMwxlDUXFfOaGmV1MRAghTQcFN8Rm6Q9LaYOOarZfyCupAAAczSgw65wcxwFWttYNQJkbQoh9oeCG2Kz61NxYgjVNBxdqbmgqOCHEjlBwQ2yWsCu4SndvqUYMbqxgIT8+c0PBDSHEntQruMnKyjI6hs8YQ1ZWltmdIsQSOImxzE2VBRazqeW8fFExZW4IIUQU9QpugoODcfPmTYPjBQUFCA4ONrtThFiC0WEpAGjgX/TWNCxFe0sRQuxRvYIbxpiQ7tZ1584dODo6mt0pQixBf7aUTnDT0ENTVrQzOAU3hBB7VKd1bmbPng1AM47/xhtvwNnZWbhNpVLhyJEjiIyMtGgHCakvYW+p+4MbVRXg0HCL63EO2tlSVeIHNzQsRQixR3UKbk6ePAlAk7k5ffo05HK5cJtcLkeXLl0wd+5cy/aQkHriV7Zm9w9LNdrmmdZTUExTwQkh9qROwc2+ffsAAPHx8Vi1ahXc3d0bpFOEWIKkusxNQ+8vZYUFxbSIHyHEntSr5mb9+vUU2BCrp7dxpkQCaOtPjG3BMKmXphC+hYf5NWPWVFBMmRtCiD2q195SAwYMqPH2vXv31qszhFgSX3PD1NqshcQBUFUaHZaKatMM6w5moLWXs8FtdSaznnVuKHNDCLFHdQpufv31VwwdOhRdunTRO15VVYXU1FScOXMGEyZMsGgHCamve7OltMW0Elm1wQ0/+c8SMYA1FRRzoMwNIcT+mBTc3Lp1Cy+//DKqqqowdOhQfPjhh0bbvfnmm7hz545FO0hIfelNBQfu1d0Y2V9Kwgc3MD+6saZhKZotRQixRybV3CQlJaGwsBD//e9/a2z3n//8B+vWrbNIxwgxl94ifpoDms9GZ0vx2xSYf15O2DhT/GEpWueGEGKPTApuXn75Zfj6+uLJJ5+ssd2hQ4doET9iNQxqbmrYX4rP3KgtMC5lTbOlKLghhNgjk4alPD09sX79euzatQsADIIcxhiys7Nx7NgxvPHGG5bvJSH1UO2wlJHZUvysIovU3Tpoi3iV4te5CMENKLghhNiPOhUUx8bGAgA8PDz0jkskErRv3x5vvfUWHn30Ucv1jhAzVD8sZRh0CDU3Fsnc8MNS1pO5oYJiQog9qddU8PXr11u6H4RYHGeQualpWMqCNTdSbRBlpHC5sfHBDU0FJ4TYk3oFN7zjx48jLS0NANCpUyd07drVIp0ixBL4YSm9dW4Azd5S97PR2VKUuSGE2KN6BTd5eXkYO3Ys9u/fD09PTwBAYWEh+vfvj02bNsHHx8eSfSSkXiRSbb2JQc1NDZkbS5SmCLuCix9Q0CJ+hBB7VK/tF6ZPn46SkhKcPXsWBQUFKCgowJkzZ1BcXIyXX37Z0n0kpF709pYCACkf3BgGHdrEjWVmS0lp40xCCBFTvTI3ycnJ2LNnDzp27CgcCw8PR1JSEhUUE6shzIC6f1jKyGwpPnNjkfPyU8FV4gcUlLkhhNijemVu1Go1ZNqFynTJZDKoLZLXJ8R8QuaG1V5zY9l1brQBhTVsv0CZG0KIHapXcDNgwADMmDEDN27cEI5dv34ds2bNwsCBAy3WOULMwW8CDqbN3gizpWooKLbIOjfaYSkrytzQIn6EEHtSr+Dm448/RnFxMYKCgtC2bVu0bdsWwcHBKC4uxurVqy3dR0LqhdMZalIzdq/mxujeUvdlecw5rxXV3NAKxYQQe1SvmpvAwECcOHECe/bswfnz5wEAHTt2RExMjEU7R4g5+GEpAGAqVuM6N/cKis0/773tF8TP3NBUcEKIPapT5mbv3r0IDw9HcXExOI7DoEGDMH36dEyfPh3du3dHp06d8McffzRUXwmpE34RP0C7SrG0+mGp5q5yAEB2UZn5Jxa2XxC/5kYCWsSPEGJ/6hTcrFy5EpMnT4a7u7vBbR4eHpgyZQpWrFhhsc4RYg6JTnDDGGosKPZ01gQ35VVqswMBYfsFa1ihWEKZG0KI/alTcHPq1CkMHjy42tsfffRRHD9+3OxOEWIJupkbpmI17goud7j3rVCpMq8+Rdh+gTI3hBAiijoFN7m5uUangPMcHBxw8+ZNsztFiCXoLl2j1p0tZSRzI5fqBDdKM4MbK1qhmGpuCCH2qE7BTUBAAM6cOVPt7f/88w9atGhhdqcIsQSO44TsDdOdLWWk5saSwQ2k1lNzI9XuhG6JPbMIIaSpqFNwM3ToULzxxhsoLy83uK2srAyLFi3CsGHDLNY5QszFr3Wj1p0tZWwquISDVBsIKc2cMmVNNTecdh6YysiWE4QQYqvqNBX89ddfx48//oiwsDAkJCSgffv2AIDz588jKSkJKpUK//d//9cgHSWkPiQcBzWYZhG/GmZLadoCKpi/1g2/QjGsYIViYRE/0Do3hBD7Uafgxs/PD3/99RdeeuklLFiwQChS5DgOsbGxSEpKgp+fX4N0lJD64KQcUFV7zQ3AL+THzF7rhrOiFYo5YXFCCm4IIfajzov4tWnTBr/++itu376NS5cugTGG0NBQNGvWrCH6R4hZ+OngmswNX3NjPKNSoa21uV1aiQBPp/qfVFih2HoyNzQsRQixJ/XafgEAmjVrhu7du6NHjx4U2BCrdW9ncNSaueEt/Kn6onmTzimsUCx+cMPPlqKCYkKIPal3cGNJSUlJCAoKgqOjI3r27ImjR49W2/bHH39Et27d4OnpCRcXF0RGRuLrr79uxN6SpoTjdwY3oeaGl557x7xzWtMKxTQVnBBih0QPbjZv3ozZs2dj0aJFOHHiBLp06YLY2Fjk5eUZbe/l5YX/+7//w6FDh/DPP/8gPj4e8fHx2LVrVyP3nDQF/Dp+ml3Bq1+h2KKsqOZGyNzQIn6EEDsienCzYsUKTJ48GfHx8QgPD8eaNWvg7OyMdevWGW3fr18/PPHEE+jYsSPatm2LGTNm4IEHHsCff/7ZyD0nTQGfudGsc1P9CsWWPaf11NxQ5oYQYo9EDW4qKytx/Phxvd3EJRIJYmJicOjQoVrvzxhDSkoKLly4gD59+jRkV0kTxRcU669z07CZG36FYququaHMDSHEjtR5tpQl5efnQ6VSGUwf9/Pzw/nz56u9X1FREQICAlBRUQGpVIpPPvkEgwYNMtq2oqICFRUVwtfFxcWW6TxpEu4VFJtec2P2Oa1ohWLK3BBC7JGowU19ubm5ITU1FXfu3EFKSgpmz56NkJAQ9OvXz6BtYmIiFi9e3PidJFZBoltQLNTc1Bx0mJ3jsKKaG2ERP1rnhhBiR0QNbry9vSGVSpGbm6t3PDc3F/7+/tXeTyKRoF27dgCAyMhIpKWlITEx0Whws2DBAsyePVv4uri4GIGBgZa5AGL1OIkImRs+uFE2cOGyCWgRP0KIPRK15kYulyMqKgopKSnCMbVajZSUFERHR5v8OGq1Wm/oSZdCoYC7u7veB7Ef9VnnxuxzCuvcUOaGEELEIPqw1OzZszFhwgR069YNPXr0wMqVK1FaWor4+HgAQFxcHAICApCYmAhAM8zUrVs3tG3bFhUVFfj111/x9ddf49NPPxXzMoiV0huWqmWFYouhmhtCCBGV6MHNmDFjcPPmTSxcuBA5OTmIjIxEcnKyUGSclZUFieRegqm0tBRTp07Fv//+CycnJ3To0AHffPMNxowZI9YlECvG6a5z42Ba5sasrReguyu4+AGFq8wVAFBSWSJyTwghpPGIHtwAQEJCAhISEozetn//fr2vlyxZgiVLljRCr4gtMFpQXE3NTYiPC67cLMWgcPM2f723K7j4NTceCg8AFNwQQuyL6Iv4EdKQjBYUV5O56RPqo2lr5nwpa9oVnIalCCH2iIIbYtOE2UJ6mZtapoKbOxfcClcopkX8CCH2hIIbYtP4YSlTMjdCfY6Z5xRWKFapRA8q+OCGZksRQuwJBTfEpukNS0lqXueGA78PlZnn1M6WAiD6FgwS7be4GhTcEELsBwU3xKbdG5bCvang1axQfC9zY5maG0D8oSkhc6Om4IYQYj8ouCE2TW9YqtbMjZa5I0m6wY3IRcVCcEeZG0KIHaHghtg0PhujNqHmht9B3OyaG93gRuTp4PwKxWLX/hBCSGOi4IbYNOOZG+PZFD5zY3YgoLPoJKwkc0NTwQkh9oSCG2LT+IJi/e0Xqsmm8DU35hYUcxwg065SbC01NzRbihBiRyi4ITbt3saZrNaNM/nZUtdu3zX/vML+UuJmTGhYihBijyi4ITZNf+NMnYJiI7/sD125BQDYdTbX7PPe2xlc3JobPmCjgmJCiD2h4IbYNL5IWK3SWaFYc8Cg7alrhRY7r5C5EbnmhoalCCH2iIIbYtPkjpqApqpceS9zA1Rfd2MpVHNDCCGioeCG2DSZkyaDUlmmuldzA1Rbd2Mp92puKLghhJDGRsENsWlSYzU3QK2bZ5rrXs2NdQQ3VFBMCLEnFNwQm6Y3FVwihTDfu4EzN3CwjpobWueGEGKPKLghNk1v40xAf8ZUQ57XQVtzUyVu5oamghNC7BEFN8Sm6c2WAmpd68ZShJ3Bq9mks7HQVHBCiD2i4IbYNCFzw2cuhFWKDYOO4V1aWu682pobKigmhJDGR8ENsWnCZpgmZG6eeyQYANDSw9H8EwvBDa1zQwghjY2CG2LT9AqKgRprbjiDI2acVwhuxF2hmIIbQog9ouCG2DTJ/QXFQubGcLiI4zfOtMB579XcWEfmhgqKCSH2hIIbYtPuZW60B2rYGVzCb7JpgTiAk1lJzY32W5ymghNC7AkFN8SmSbTvcMZHNybMlmKWyN1IraPmRtgV3SL5KEIIaRoouCE2jZPen7mpoeaGH5ayRObGSmpu+HVuqOaGEGJPKLghNk3IXAg1N9WvP8OvCWORmhsH66i54a+fghtCiD2h4IbYNIm0moLiBs7cCFPBRV6hmGZLEULsEQU3xKYJmYv7p4IbqbnhhLng5kc3wvYLIq9QTMENIcQeUXBDbJrhVPDqVygWhqUsUXPDTwUXe7YUPxUcjKaDE0LsBgU3xKbdKyg2PXNzq7QSKrV5gcC9qeAir3Oj8y1O2RtCiL2g4IbYNIlBQbFpKxTv+OeGeSfWZm7EXueGuzfWRptnEkLsBgU3xKYJmRtVXWpugOJy84ISa6m54aeCA7RKMSHEflBwQ2yaxCC4kWs+qyqNtL4X3UjM3GjK2mpuABqWIoTYDwpuiE1zkGm3H1Bqf7E7emg+lxcZtNXN3Eg486Iba6m50RuWouCGEGInKLghNk3qcF9wo3DTfC4vNmirG85IzQxu7m2/YD3DUhTcEELsBQU3xKYJwU2V9he7g6Pms6rCoK1ulsPc2IbffsHYSsiNiQqKCSH2iIIbYtMkDppf7iqltubGQaH5rDQS3Ojez9xhKe32C6KvUKw7FVxNwQ0hxD5QcENsmkS7LbgwFbym4Ea35sbc7wx++wWR95bSLSjenbVbxJ4QQkjjsYrgJikpCUFBQXB0dETPnj1x9OjRatt+8cUX6N27N5o1a4ZmzZohJiamxvbEvvG/29X8NGipNrgxMiylu26f2ZkbqXXsCq47LHWt5JqIPSGEkMYjenCzefNmzJ49G4sWLcKJEyfQpUsXxMbGIi8vz2j7/fv3Y9y4cdi3bx8OHTqEwMBAPProo7h+/Xoj95w0BfxUcDBt9kbI3BhOBS8uuxeIuDk6mHVeoeZG5NlSuhw4866JEEKaCtGDmxUrVmDy5MmIj49HeHg41qxZA2dnZ6xbt85o+2+//RZTp05FZGQkOnTogC+//BJqtRopKSmN3HPSFOhPhdYNbsoN2rb3dxP+b27mBg7WsUKxLgcJBTeEEPsganBTWVmJ48ePIyYmRjgmkUgQExODQ4cOmfQYd+/eRVVVFby8vIzeXlFRgeLiYr0PYj8kOqvxMTWrcRE/R5kU7f00AY65i/lyVlJzo6uzd2exu0AIIY1C1OAmPz8fKpUKfn5+esf9/PyQk5Nj0mO8+uqraNmypV6ApCsxMREeHh7CR2BgoNn9Jk0Hv/0CoF2lmJ8KbqSgGAActYv+qc2Mbqyl5gYA2jdrD0B/zRtCCLFlog9LmeO9997Dpk2bsG3bNjg6Ohpts2DBAhQVFQkf165RUaU90R1eYgyAgzZzU01www9jmbkpuLBCsTXU3PAzpmgRP0KIvRB1EN7b2xtSqRS5ubl6x3Nzc+Hv71/jfT/44AO899572LNnDx544IFq2ykUCigUCov0lzQ9upkbpmI1zpYC7u0pZW7mxlp2BQfuBTcMtHEmIcQ+iJq5kcvliIqK0isG5ouDo6Ojq73f0qVL8fbbbyM5ORndunVrjK6SJkq3Llitrn1Yis/0mLuDtrXsCg5Q5oYQYn9Enz4xe/ZsTJgwAd26dUOPHj2wcuVKlJaWIj4+HgAQFxeHgIAAJCYmAgDef/99LFy4EN999x2CgoKE2hxXV1e4urqKdh3EOnEcB07CgamZJmCpZVhKYqlhKe1sKYi8QjGgO9RGwQ0hxD6IHtyMGTMGN2/exMKFC5GTk4PIyEgkJycLRcZZWVnCKrMA8Omnn6KyshJPPfWU3uMsWrQIb775ZmN2nTQRnARgam1BcS3DUnymx5ZmS/FbMJibjSKEkKZC9OAGABISEpCQkGD0tv379+t9nZmZ2fAdIjZFwnFQg9W6iB/fFrBEzY117AoO6AxL0caZhBA70aRnSxFiCr6oWK0b3NSSuTF7KriV7AoO0LAUIcT+UHBDbB6/kJ9mET9tcKNWAmrDIaN7BcXmndNadgUHdGZL0bAUIcROUHBDbB4nMZK5AWrcGdxSmRtrqrmhzA0hxF5QcENsHidkbqAf3BgZmrLUbClrqrkRhqWo5oYQYicouCE2T29YSuIAQJueMZK5kQizpczM3AgrFIsf3NCwFCHE3lBwQ2ye1EETsVSWKzXjTjUs5GexmhsrWqGYCooJIfaGghti81ybaYKZu8Xa6d81LOR3teAuAODsjSLzTupgPcNSVHNDCLE3FNwQmyfhp4KrtOkYuZvmc0WJQdtLeXcAABsPXTXrnFZVUEx7SxFC7AwFN8TmSaTazAUf3Dh5aj6X326wcwrr3FRVNdg5TEXDUoQQe0PBDbF59zI32l/uMmfN56ryhjspX3NjDZkbGpYihNgZCm6IzTMYlhK2YGi44IaTaXYFh1oNphY3qKDZUoQQe0PBDbF5Et3tF4AaZ0tZCj9bSnMecYuKaZ0bQoi9oeCG2LxqMzfV7C9lCULNDcSfMSVsnEnDUoQQO0HBDbF5/CJ+Qs2NMCzVcMENdIMbketu+JobGpYihNgLCm6IzeNnSzGDYakGrLmxoswNzZYihNgbCm6IzeOHpVQGBcWVDXZOTiK5twunlQxL0To3hBB7QcENsXn3hqW0v9yl1c+WenlgKAAgpqOv2eflrGSVYqq5IYTYGwpuiM3jMzfMIHNjWHPj7arZmkHuYIFvDStZpZiCG0KIvaHghtg8gxWKa6i54TfOtMTSNELmRuRVimlYihBibyi4ITbPYIXiGqaC88GNygIzi4S1bkTO3HDQXpNa/NWSCSGkMVBwQ2ye4SJ+2uCm8q5hW20NsEWmTcuso+ZGymmCLBqWIoTYCwpuiM0zWMTPI1DzOT/dsK0wbdr883JSPrgRN2PiINH0o0ot/iaehBDSGCi4ITaPu3+2lFeI5nPJDYO2wswqSwxL8WvdKMUNKvjgRsnEzSARQkhjoeCG2DwpX1DMp2PkLprPRnYF54elVBZI3XBWsjO4VKLpB9XcEELsBQU3xOYZFBTLnDWfq+4C92Vo+GEpi+xUwNfcVImbMXHgtJkbNWVuCCH2gYIbYvMMhqVkTtpbmMFaN/yiwhYZluJrblTiBhUyiQwABTeEEPtBwQ2xeVLtgnwqJZ+5cbp3Y5X+jClpg9TciJy5oZobQoidoeCG2DxHF80v9/I72sJeqQzQZjNQVabX1pKzpeBgHTU3QnBDmRtCiJ2g4IbYPLmTdip0hU6Qwdfd3LdKMV9QrLZEQbGDJoASveaGpoITQuwMBTfE5hkMSwH3hqbuG5biOAsOSwkrFFvHIn40W4oQYi8ouCE2z2ARPwCQafeXum9YSmrJRfysZFdwGpYihNgbCm6IzRMyN3rBjc50cB0S7XeERbZf4GtuRF6hWJgtRQXFhBA7QcENsXlC5sbosJR+5oazaOZGW3NjLSsUU+aGEGInKLghNq9OmRt+V3CLFBRrp4LTbClCCGlUFNwQmyfht18wmrmpZraURda50Q5LWclsKQpuCCH2goIbYvOkDvcKioVaGrmr5nNFiX5bC86WAl9QLPbeUtrZUlRzQwixFxTcEJsncbj3NhdmTDl6aD6XF+m1Vcg0gUBZlfkBibD9AtXcEEJIoxI9uElKSkJQUBAcHR3Rs2dPHD16tNq2Z8+exahRoxAUFASO47By5crG6yhpsviCYkBnrZtqghtXhSYQKK2wQHBDNTeEECIKUYObzZs3Y/bs2Vi0aBFOnDiBLl26IDY2Fnl5eUbb3717FyEhIXjvvffg7+/fyL0lTZVUJ7ipLXPjLNdkbkorzA8EOJl2tlRlpdmPZQ7aOJMQYm9EDW5WrFiByZMnIz4+HuHh4VizZg2cnZ2xbt06o+27d++OZcuWYezYsVAoFI3cW9JUcRIO0MY3hpmbQr22Mm3xsdISs6UcNQsFqssramnZsChzQwixN6IFN5WVlTh+/DhiYmLudUYiQUxMDA4dOmSx81RUVKC4uFjvg9gXjuMg5WdM1ZK5kUnvTQU3dzq4xFETgLPy8lpaNiy5VA4AqFSLm0EihJDGIlpwk5+fD5VKBT8/P73jfn5+yMnJsdh5EhMT4eHhIXwEBgZa7LFJ0yHRzpgSMjdOnprP9wc3OsXHVSo1zMEp+MyNuMGNQqIJsiqU4maQCCGksYheUNzQFixYgKKiIuHj2rVrYneJiEDI3Cj5zI2n5vN9w1JyqeWCG2vJ3Cik2uBGRcENIcQ+OIh1Ym9vb0ilUuTm5uodz83NtWixsEKhoPocYiRz00zzufSWXjuZTnCjVJk3LMU5ahYKVFeIG1QIw1IqGpYihNgH0TI3crkcUVFRSElJEY6p1WqkpKQgOjparG4RG+Ug027BwAc3rr6az1WlQGWp0E4q4SDVLlNsa5kbJVNSUTEhxC6IlrkBgNmzZ2PChAno1q0bevTogZUrV6K0tBTx8fEAgLi4OAQEBCAxMRGApgj53Llzwv+vX7+O1NRUuLq6ol27dqJdB7F+MoVmincVv36N3FWzv1TVXeBOHuAVfK+tlINKzVBpqZqbCpGDG4d7mctKVaUwe4oQQmyVqD/lxowZg5s3b2LhwoXIyclBZGQkkpOThSLjrKwsSCT3kks3btxA165dha8/+OADfPDBB+jbty/279/f2N0nTYhBcMNxgIsPUHgVKL15X3AjQXmVGlVmD0tpMzdlIs+WksiF/1eqKuHMbxpKCCE2SvQ/4RISEpCQkGD0tvsDlqCgoHt7AxFSBwbBDaAZmiq8CtzRr/vii4rNH5ayjsyNVCKFg8QBSrUS5Spx+0IIIY3B5mdLEQIADnIjwY2Ltu7mjv6K2HxRcaXS3GEpvuZG/FlKfN0NFRUTQuwBBTfELsgcjWVufDSfS2/qt3WwUEGxEz9bSvxsCU0HJ4TYEwpuiF2QaTfErEvmxuyaGyvK3NB0cEKIPaHghtiFamtugIavuRF5KjhAmRtCiH2h4IbYBZlcuyGmseDm/mEpvubG3Kng2uAGVVVgKlXNjRsYBTeEEHtCwQ2xC3UbltLU3JhbUCzRWRnbWhbyo+CGEGIPKLghdsF4QbHxzI2bowwAUHS3yqxzCpkbWM8WDDQVnBBiDyi4IXaBH5aqqtDZfsBFO1uq8o7eFgzNXTWBwK1S84pvOZ0FKFW3b5v1WOZyctDM3CqrKhO1H4QQ0hgouCF24d6wlM5Qk8INcNBmV3SGppy1a+KUVVmuTib/s88s9lj14S53BwAUVxaL2g9CCGkMFNwQuyBz0gQs5aU6Q00cpzNjSje40QRCZZWW22SSk8trb9SA+OCmqKJI1H4QQkhjoOCG2AU3L02G5s7t+2pOmmn3lLqZJhxykmkCobuV5mdu3AbFAADkga3NfixzuCsoc0MIsR8U3BC7oHDSZGOUlWqo1TqL8/l11nzOTxcOCcNSFghuZC1bAgDUd+6Y/VjmoGEpQog9oeCG2AW54709YvVmTDVro/lceFU4xAc3lsjcSFxcAQCqOyVmP5Y5KLghhNgTCm6IXZDKJJDw69eU6dTSeGqHiwqzhENO2pqbm3fMn74t9fQAAKiLxK114YelSirEDbIIIaQxUHBD7Aafvakq18nICMHNNeHQXW0h8fGr5k/fljZrBgBQijwVnDI3hBB7QsENsRv8Qn6V5TqZG49AzeeyAkCb1ci6dddi55R6aoIb1e1Ciz1mfVBwQwixJxTcELthNHPj6A5oV+/FrUsAgAkPBwk3q9Tm7QzOZ27EXsTPQ6EZHiuuKAZj5l0TIYRYOwpuiN1QOGuCG721bgCgeTvN59TvNF+63luTpkJpXlGxQzNPAICqoEDUoILP3CiZEmVKWqWYEGLbKLghdsPZQxO0lBbdVygs02xNgLJCAICjg1S4ydzp4FIfzRYPrKpK1KJiJwcnOHCa4I6Gpgghto6CG2I3XDw0O2OXFt23Z9QjszSf8y8CACQSDgoHzbeGuVswSORySD09AQBVeXk1N25AHMcJM6ZolWJCiK2j4IbYDSG4Kbwvc+PdXvM5Px1Qa/aeqlBqPv972/whHAdfzRYPylzxghuAiooJIfaDghtiN1yaaYal7t4/LOUVDEhkQFUpUJSld9Plm+avLCxr1QoAUHHxgtmPZQ4huKmg4IYQYtsouCF2o9phKakM8I/Q/P/6cQBAVBvNLCcOnNnnlWqLivM/+dTsxzKHr7Mmg5Rdmi1qPwghpKFRcEPsRrXDUgDQqpvm87/HAABtvJwBACXlVYZt64hVah5DXVpq9mOZo7W7ZsHCq8VXa2lJCCFNGwU3xG64eGqCm6oKFSru3he0tOqh+ZzxOwCgpEKz0N/nv18x+7weI0YI/2famh4xBLkHAQCySrJqbkgIIU0cBTfEbsgUUrhop4PfzrlvFeJ2AwGJA5B7Brh1GVUqTRBSVGZ+5sa5a6Twf2W2eENClLkhhNgLCm6IXWnWwgUAcDvnviEiZy8gqLfm/2k/45kemkCgYwt3s88pcXGBPCgIAFB69G+zH6++2rhrdkDPLs1GpaqyltaEENJ0UXBD7Eozf21wk21k/6iOwzWf0/6H5q6aIazT14sssrKwS29N4FR2KtXsx6qv5o7N4SJzgZqp8W/Jv6L1gxBCGhoFN8SueLXUBDc3r5UY3thhGAAOuH4cwVXpwuGbJUYKkOuIH5oq3LTZ7MeqL47jhOxNRlGGaP0ghJCGRsENsSst2mk2kMy5XARV1X3FvW5+QOuHAABe574RDqfnmb/WjcvDDwv/r7h82ezHq68OXh0AAGdunRGtD4QQ0tAouCF2xauFC5zcZFBWqZGbaWQxu+hpms+nt6CNs6aY+K/L+Wafl9+CAQBKdu8x+/Hq6wHvBwAAqXmpovWBEEIaGgU3xK5wHIeA9poF+v69cNuwQYdhgE8HoOouZrvtBgBsOWaZ+pQWS94GANzetAlMZd6eVfXV3b87AE1wQ3tMEUJsFQU3xO4EdvACAFw5mWdYLMxxQL8FAIBhJVsQyv0LqcT8VYoBwH34cEg9PKDMyUHxL79Y5DHrqrV7a7TzbAclU2L31d2i9IEQQhoaBTfE7oR09YFUJsGt66W4dq7AsEH4CKDtQEjVFfhY9hHuFuUjM9/81YUlCgW8Jk0CAOR9sBzK20YyR41gRFvNooJfn/vaIjPBCCHE2lBwQ+yOo4sMHR7yBwD8/Uum8ezNE2sAVz+0l/yLrfLF+H73XxY5t9fECZAFBkKZl4d/X5oKVmX+IoF1NSpsFJwdnHGl6Ap+yRAng0QIIQ2Jghtil7o/FgypgwQ5V4pwcreR7QhcfYFnt6PS2R+hkuuIP/8Cbpw/bPZ5JQoFAlZ+CE6hQFlqKq6/Mg/qCvOnmteFm9wNz0c8DwBIPJKIrGLajoEQYlsouCF2ycVTgV5PtQMAHNp2GWd+v26YwfELh+yFPbju0Br+XAH8Ng2B8qeZwG3zti9w6tQJASuWAwBKkpOR+fRolB49atZj1tXEThPxgPcDKK4sxqRdk3Amn6aGE0JsB8fsbNC9uLgYHh4eKCoqgru7+Uvrk6bt9+8v4PSB6wCAdlG+6DkiBJ6+znptsv79Fxe+iMcgThOAME4Crl0M0PkpIHSQZuuGerjz50HcmDcPqgJN3Y/Lw9Fwf2wYXHo/ApmvrxlXZZr8snw8t+s5XCm6AgfOAc90fAb/6fgftHBt0eDnJoSQuqrL72+rCG6SkpKwbNky5OTkoEuXLli9ejV69OhRbfstW7bgjTfeQGZmJkJDQ/H+++9j6NChJp2LghuiizGGk79l4fD2y2AMAAe0bOeJ4C7e8G3jDu9AV8gdHXAsswCr123A8+wH9Jbey3IwTgLOrzMQEAW0eADwbg94hwEu3pranVoo8/Nxc/XHKNy6FdCZHq4I7wjX3n3g9EAEFKGhkLVsCc7BweLXX1RRhLcPv41dmbsAABJOgp7+PdG7VW9E+kQizCsMCqnC4uclhJC6alLBzebNmxEXF4c1a9agZ8+eWLlyJbZs2YILFy7A18hfr3/99Rf69OmDxMREDBs2DN999x3ef/99nDhxAp07d671fBTcEGNuZpXgyP+u4OrpW/o3cICHjxN8At2gdJJgf1YBsm9dQ3eHk3hYehIdpZegkNyBAyr1YhkmVQDuLcG5B2jqd1y8AWdvwKU54OgJKNw0H3JXQOGGyptFKPp1D+4cPIzyM2cNO+jgAFlAS8j8W0Dm7w+pd3M4eHlB2swLEjdXSN3cIHF1g9TNFRJnZ3BOTpA4OYGTSk26/t///R0bz27E0Rz94TEHzgG+zr5o7tQczR2bo7lTc3g5eul9zX92l7uDMyGgI4SQ+mhSwU3Pnj3RvXt3fPzxxwAAtVqNwMBATJ8+HfPnzzdoP2bMGJSWlmLHjh3CsYceegiRkZFYs2ZNreej4IbUpKSgHJeO5+FGeiHyr5Xgzm3Ti305VMGBq4SMq4ADVwmp9mspVwkpp/m/AzT/l3KVkEANCacCBzU4qCDhNJ+ZEqi6I0VVKQd1GcDK1IBaDY4xAAwcADDN1hGaY2rtMQYODODbMQZIAE4KgOM0wRcHzTFOcwwSDpxE8xkcB6VEjVJOibuowl1OhSpODZWEgXGASgKoJQwqDmDcvf+rJQxqjoNaon0YcJBIJJBwHCSQQCLhIOEk4KA5j4TjwEHTH07bDtq2nIQT2kH7WJr+8vfR3q4NonSPQ+c23bacRPs4nETzPPHXDoAvOxSCMk7n/5oOaB9Pm6Xjb9E+mYx/Xvlj2hNwmpMafZdwOn3Xv4W/Ht3+8fe593Cczr+Gj8P3R3MHB4kEzjIp31C4JG3Le4/G8XfhdB9Jv3fVxa33Hkb/sNAP/Z7r/o8zvIPBYxs+S/faSyQMCie14e16ze5/3BquBQA4w1JUTu9xDe9s7DUzaFNT4K/zPtI9pvtYRs9qcPC+AxJJTbcaHLn3faD/PBttAwByF80faFquMle4yDX793FyORx8fAzOaI66/P62fJ67DiorK3H8+HEsWLBAOCaRSBATE4NDhw4Zvc+hQ4cwe/ZsvWOxsbHYvn270fYVFRWo0JmNUlxsZMl9QrTcvBzRdVBrdB3UGgBQVlKJm9dKcOvfUtwpLEdpYQVKCytQVlKFirtKlN+tArR/HjDIUMVkqGIu5ndEBsBT+2ElOABS7UetdH/f1LAYM9O5WZw1m0lT5nrnX/Q49p7Y3SBautsRO0VGImjT96L1RdTgJj8/HyqVCn5+fnrH/fz8cP78eaP3ycnJMdo+JyfHaPvExEQsXrzYMh0mdsfJTY7W4c3ROry50dsZY6gqV0FZpYaySgVVlRrKKjWqKlUovlOJotIq3CmtQnm5EuUVSpRXqKCsVKGqUg2lUg2VSg2mZmBqBqhVkKiVgEoFiVql/VoFqNWAWpuhUTNwTH0vO6PWfAZjQpCl+b/2Nu0HJ9wGnXY67cGBY0xziHHgoP0/OL3bockN3Xs84aE4AIzPK+kc0z8V/5ci0/k/9P5f3e3G1GcIzNL3qevjVd++2hR6vYb66t5nY+fnWzJjfWA1ncaSz5n+e0mXGkoUuRi+H03VEPer8eoa+341aIhrkEkcIOU0f/5wMlm9+mUpogY3jWHBggV6mZ7i4mIEBgaK2CNiSziOg9zJAXInw9taNn53CLFDk8TuALFCogY33t7ekEqlyM3N1Tuem5sLf39/o/fx9/evU3uFQgGFgmZ7EEIIIfZC1EX85HI5oqKikJKSIhxTq9VISUlBdHS00ftER0frtQeA3bt3V9ueEEIIIfZF9GGp2bNnY8KECejWrRt69OiBlStXorS0FPHx8QCAuLg4BAQEIDExEQAwY8YM9O3bF8uXL8djjz2GTZs24dixY/j888/FvAxCCCGEWAnRg5sxY8bg5s2bWLhwIXJychAZGYnk5GShaDgrKwsSnelsDz/8ML777ju8/vrreO211xAaGort27ebtMYNIYQQQmyf6OvcNDZa54YQQghpeury+5s2ziSEEEKITaHghhBCCCE2hYIbQgghhNgUCm4IIYQQYlMouCGEEEKITaHghhBCCCE2hYIbQgghhNgUCm4IIYQQYlMouCGEEEKITRF9+4XGxi/IXFxcLHJPCCGEEGIq/ve2KRsr2F1wU1JSAgAIDAwUuSeEEEIIqauSkhJ4eHjU2Mbu9pZSq9W4ceMG3NzcwHGcRR+7uLgYgYGBuHbtml3tW2WP122P1wzQddN12wd7vO6mcM2MMZSUlKBly5Z6G2obY3eZG4lEglatWjXoOdzd3a32zdGQ7PG67fGaAbpue0PXbT+s/Zpry9jwqKCYEEIIITaFghtCCCGE2BQKbixIoVBg0aJFUCgUYnelUdnjddvjNQN03XTd9sEer9vWrtnuCooJIYQQYtsoc0MIIYQQm0LBDSGEEEJsCgU3hBBCCLEpFNwQQgghxKZQcGMhSUlJCAoKgqOjI3r27ImjR4+K3SWzvPnmm+A4Tu+jQ4cOwu3l5eWYNm0amjdvDldXV4waNQq5ubl6j5GVlYXHHnsMzs7O8PX1xSuvvAKlUtnYl1Kt33//HcOHD0fLli3BcRy2b9+udztjDAsXLkSLFi3g5OSEmJgYpKen67UpKCjA+PHj4e7uDk9PTzz33HO4c+eOXpt//vkHvXv3hqOjIwIDA7F06dKGvrQa1XbdEydONHjtBw8erNemKV53YmIiunfvDjc3N/j6+mLkyJG4cOGCXhtLva/379+PBx98EAqFAu3atcOGDRsa+vKMMuWa+/XrZ/B6v/jii3ptmtI1A8Cnn36KBx54QFiQLjo6Gjt37hRut7XXmVfbddvia10tRsy2adMmJpfL2bp169jZs2fZ5MmTmaenJ8vNzRW7a/W2aNEi1qlTJ5adnS183Lx5U7j9xRdfZIGBgSwlJYUdO3aMPfTQQ+zhhx8Wblcqlaxz584sJiaGnTx5kv3666/M29ubLViwQIzLMerXX39l//d//8d+/PFHBoBt27ZN7/b33nuPeXh4sO3bt7NTp06xxx9/nAUHB7OysjKhzeDBg1mXLl3Y4cOH2R9//MHatWvHxo0bJ9xeVFTE/Pz82Pjx49mZM2fY999/z5ycnNhnn33WWJdpoLbrnjBhAhs8eLDea19QUKDXpiled2xsLFu/fj07c+YMS01NZUOHDmWtW7dmd+7cEdpY4n195coV5uzszGbPns3OnTvHVq9ezaRSKUtOTm7U62XMtGvu27cvmzx5st7rXVRUJNze1K6ZMcZ+/vln9ssvv7CLFy+yCxcusNdee43JZDJ25swZxpjtvc682q7bFl/r6lBwYwE9evRg06ZNE75WqVSsZcuWLDExUcRemWfRokWsS5cuRm8rLCxkMpmMbdmyRTiWlpbGALBDhw4xxjS/QCUSCcvJyRHafPrpp8zd3Z1VVFQ0aN/r4/5f8mq1mvn7+7Nly5YJxwoLC5lCoWDff/89Y4yxc+fOMQDs77//Ftrs3LmTcRzHrl+/zhhj7JNPPmHNmjXTu+ZXX32VtW/fvoGvyDTVBTcjRoyo9j62cN2MMZaXl8cAsAMHDjDGLPe+njdvHuvUqZPeucaMGcNiY2Mb+pJqdf81M6b5hTdjxoxq79PUr5nXrFkz9uWXX9rF66yLv27G7Oe1ZowxGpYyU2VlJY4fP46YmBjhmEQiQUxMDA4dOiRiz8yXnp6Oli1bIiQkBOPHj0dWVhYA4Pjx46iqqtK75g4dOqB169bCNR86dAgRERHw8/MT2sTGxqK4uBhnz55t3Auph4yMDOTk5Ohdo4eHB3r27Kl3jZ6enujWrZvQJiYmBhKJBEeOHBHa9OnTB3K5XGgTGxuLCxcu4Pbt2410NXW3f/9++Pr6on379njppZdw69Yt4TZbue6ioiIAgJeXFwDLva8PHTqk9xh8G2v4eXD/NfO+/fZbeHt7o3PnzliwYAHu3r0r3NbUr1mlUmHTpk0oLS1FdHS0XbzOgOF182z5tdZldxtnWlp+fj5UKpXemwEA/Pz8cP78eZF6Zb6ePXtiw4YNaN++PbKzs7F48WL07t0bZ86cQU5ODuRyOTw9PfXu4+fnh5ycHABATk6O0eeEv83a8X00dg261+jr66t3u4ODA7y8vPTaBAcHGzwGf1uzZs0apP/mGDx4MJ588kkEBwfj8uXLeO211zBkyBAcOnQIUqnUJq5brVZj5syZ6NWrFzp37iz0yxLv6+raFBcXo6ysDE5OTg1xSbUyds0A8Mwzz6BNmzZo2bIl/vnnH7z66qu4cOECfvzxRwBN95pPnz6N6OholJeXw9XVFdu2bUN4eDhSU1Nt+nWu7roB232tjaHghhg1ZMgQ4f8PPPAAevbsiTZt2uC///2v1bx5ScMYO3as8P+IiAg88MADaNu2Lfbv34+BAweK2DPLmTZtGs6cOYM///xT7K40muqu+YUXXhD+HxERgRYtWmDgwIG4fPky2rZt29jdtJj27dsjNTUVRUVF2Lp1KyZMmIADBw6I3a0GV911h4eH2+xrbQwNS5nJ29sbUqnUoNI+NzcX/v7+IvXK8jw9PREWFoZLly7B398flZWVKCws1Guje83+/v5GnxP+NmvH97Gm19Xf3x95eXl6tyuVShQUFNjM8wAAISEh8Pb2xqVLlwA0/etOSEjAjh07sG/fPrRq1Uo4bqn3dXVt3N3dRfvDoLprNqZnz54AoPd6N8VrlsvlaNeuHaKiopCYmIguXbpg1apVNv06A9VftzG28lobQ8GNmeRyOaKiopCSkiIcU6vVSElJ0RvnbOru3LmDy5cvo0WLFoiKioJMJtO75gsXLiArK0u45ujoaJw+fVrvl+Du3bvh7u4upEitWXBwMPz9/fWusbi4GEeOHNG7xsLCQhw/flxos3fvXqjVauGHRnR0NH7//XdUVVUJbXbv3o327duLPjRjqn///Re3bt1CixYtADTd62aMISEhAdu2bcPevXsNhs0s9b6Ojo7Wewy+jRg/D2q7ZmNSU1MBQO/1bkrXXB21Wo2KigqbfJ1rwl+3Mbb6WgOgqeCWsGnTJqZQKNiGDRvYuXPn2AsvvMA8PT31Ks6bmjlz5rD9+/ezjIwMdvDgQRYTE8O8vb1ZXl4eY0wzlbJ169Zs79697NixYyw6OppFR0cL9+enFD766KMsNTWVJScnMx8fH6uaCl5SUsJOnjzJTp48yQCwFStWsJMnT7KrV68yxjRTwT09PdlPP/3E/vnnHzZixAijU8G7du3Kjhw5wv78808WGhqqNyW6sLCQ+fn5sWeffZadOXOGbdq0iTk7O4s6Jbqm6y4pKWFz585lhw4dYhkZGWzPnj3swQcfZKGhoay8vFx4jKZ43S+99BLz8PBg+/fv15sKe/fuXaGNJd7X/FTZV155haWlpbGkpCTRpsrWds2XLl1ib731Fjt27BjLyMhgP/30EwsJCWF9+vRpstfMGGPz589nBw4cYBkZGeyff/5h8+fPZxzHsd9++40xZnuvM6+m67bV17o6FNxYyOrVq1nr1q2ZXC5nPXr0YIcPHxa7S2YZM2YMa9GiBZPL5SwgIICNGTOGXbp0Sbi9rKyMTZ06lTVr1ow5OzuzJ554gmVnZ+s9RmZmJhsyZAhzcnJi3t7ebM6cOayqqqqxL6Va+/btYwAMPiZMmMAY00wHf+ONN5ifnx9TKBRs4MCB7MKFC3qPcevWLTZu3Djm6urK3N3dWXx8PCspKdFrc+rUKfbII48whULBAgIC2HvvvddYl2hUTdd99+5d9uijjzIfHx8mk8lYmzZt2OTJkw0C9aZ43cauGQBbv3690MZS7+t9+/axyMhIJpfLWUhIiN45GlNt15yVlcX69OnDvLy8mEKhYO3atWOvvPKK3tonjDWta2aMsUmTJrE2bdowuVzOfHx82MCBA4XAhjHbe515NV23rb7W1eEYY6zx8kSEEEIIIQ2Lam4IIYQQYlMouCGEEEKITaHghhBCCCE2hYIbQgghhNgUCm4IIYQQYlMouCGEEEKITaHghhAiutTUVCxbtgxKpVLsrhBCbAAFN4QQURUUFGDUqFHo2LEjHBwabi/foKAgrFy5ssEenxBiPSi4IYRY3MSJEzFy5EgAQL9+/TBz5kyj7RhjiIuLw6uvvophw4ZZ5NwbNmyAp6enwfG///5bb1dkQojtarg/kwghpBYcx2HHjh0mta2srIRcLq/3uXx8fOp9X0JI00KZG0JIg5k4cSIOHDiAVatWgeM4cByHzMxMAMCZM2cwZMgQuLq6ws/PD88++yzy8/OF+/br1w8JCQmYOXMmvL29ERsbCwBYsWIFIiIi4OLigsDAQEydOhV37twBAOzfvx/x8fEoKioSzvfmm28CMByWysrKwogRI+Dq6gp3d3eMHj0aubm5wu1vvvkmIiMj8fXXXyMoKAgeHh4YO3YsSkpKhDZbt25FREQEnJyc0Lx5c8TExKC0tLSBnk1CiKkouCGENJhVq1YhOjoakydPRnZ2NrKzsxEYGIjCwkIMGDAAXbt2xbFjx5CcnIzc3FyMHj1a7/4bN26EXC7HwYMHsWbNGgCARCLBRx99hLNnz2Ljxo3Yu3cv5s2bBwB4+OGHsXLlSri7uwvnmzt3rkG/1Go1RowYgYKCAhw4cAC7d+/GlStXMGbMGL12ly9fxvbt27Fjxw7s2LEDBw4cwHvvvQcAyM7Oxrhx4zBp0iSkpaVh//79ePLJJ0Hb9REiPhqWIoQ0GA8PD8jlcjg7O8Pf3184/vHHH6Nr16549913hWPr1q1DYGAgLl68iLCwMABAaGgoli5dqveYuvU7QUFBWLJkCV588UV88sknkMvl8PDwAMdxeue7X0pKCk6fPo2MjAwEBgYCAL766it06tQJf//9N7p37w5AEwRt2LABbm5uAIBnn30WKSkpeOedd5CdnQ2lUoknn3wSbdq0AQBERESY8WwRQiyFMjeEkEZ36tQp7Nu3D66ursJHhw4dAGiyJbyoqCiD++7ZswcDBw5EQEAA3Nzc8Oyzz+LWrVu4e/euyedPS0tDYGCgENgAQHh4ODw9PZGWliYcCwoKEgIbAGjRogXy8vIAAF26dMHAgQMRERGBp59+Gl988QVu375t+pNACGkwFNwQQhrdnTt3MHz4cKSmpup9pKeno0+fPkI7FxcXvftlZmZi2LBheOCBB/DDDz/g+PHjSEpKAqApOLY0mUym9zXHcVCr1QAAqVSK3bt3Y+fOnQgPD8fq1avRvn17ZGRkWLwfhJC6oeCGENKg5HI5VCqV3rEHH3wQZ8+eRVBQENq1a6f3cX9Ao+v48eNQq9VYvnw5HnroIYSFheHGjRu1nu9+HTt2xLVr13Dt2jXh2Llz51BYWIjw8HCTr43jOPTq1QuLFy/GyZMnIZfLsW3bNpPvTwhpGBTcEEIaVFBQEI4cOYLMzEzk5+dDrVZj2rRpKCgowLhx4/D333/j8uXL2LVrF+Lj42sMTNq1a4eqqiqsXr0aV65cwddffy0UGuue786dO0hJSUF+fr7R4aqYmBhERERg/PjxOHHiBI4ePYq4uDj07dsX3bp1M+m6jhw5gnfffRfHjh1DVlYWfvzxR9y8eRMdO3as2xNECLE4Cm4IIQ1q7ty5kEqlCA8Ph4+PD7KystCyZUscPHgQKpUKjz76KCL+v307tG0YiAIw/JoBohhkgYAgR+YGRiH2Al4h0AOYRwH2FgaGXsGLtaCoqiqFlDx9Hz5yB06/nu5utxiGIU6nUxwOf19LVVXFPM/xer2iLMtYliWez+ePNXVdx+PxiL7v43w+/3qQHPE9cdm2LYqiiKZp4n6/x+VyiXVd397X8XiMfd+j67q4Xq8xjmNM0xRt275/OMC/+Pj0bxEASMTkBgBIRdwAAKmIGwAgFXEDAKQibgCAVMQNAJCKuAEAUhE3AEAq4gYASEXcAACpiBsAIBVxAwCk8gXXDz8xFGG7MQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Paramètres principaux pour le modèle de réseaus de neurones\n",
    "layer_sizes = [2, 8, 8, 1]  # Définit l'architecture du réseau : 2 neurones en entrée, 2 couches cachées de 32 neurones, et 1 en sortie\n",
    "# layer_sizes = [2, 16, 1]  # Définit l'architecture du réseau : 2 neurones en entrée, 16 dans une couche cachée, et 1 en sortie\n",
    "learning_rate = 0.5       # Taux d'apprentissage pour la mise à jour des poids\n",
    "iterations = 5000         # Nombre maximal d'itérations pour l'entraînement\n",
    "cost_threshold = 1e-4     # Seuil de coût servant de critère d'arrêt : si le coût atteint ce niveau, l'entraînement s'arrête\n",
    "\n",
    "# Définition des cas de test pour les portes logiques, avec les résultats attendus\n",
    "test_cases = {\n",
    "    'AND': np.array([[0], [0], [0], [1]]),  # Porte AND avec les sorties cibles\n",
    "    'OR': np.array([[0], [1], [1], [1]]),   # Porte OR avec les sorties cibles\n",
    "    'XOR': np.array([[0], [1], [1], [0]]),   # Porte XOR avec les sorties cibles\n",
    "    'NAND': np.array([[1], [1], [1], [0]]),\n",
    "    'NOR': np.array([[1], [0], [0], [0]]),\n",
    "}\n",
    "\n",
    "# Dictionnaire pour stocker les coûts d'entraînement pour chaque porte logique\n",
    "costs_dict = {}\n",
    "\n",
    "# Boucle de test pour chaque porte logique\n",
    "for gate_type, expected_outputs in test_cases.items():\n",
    "    print(f\"\\nTest pour la porte logique: {gate_type}\")\n",
    "\n",
    "    # Génération des données d'entrée et de sortie pour le type de porte logique spécifié\n",
    "    X, Y = generate_logical_gate_data(gate_type)\n",
    "\n",
    "    # Entraînement du modèle pour les données de la porte logique avec des fonctions d'activation et paramètres donnés\n",
    "    parameters, costs = train_model(\n",
    "        X, Y, layer_sizes, learning_rate, iterations,\n",
    "        cost_threshold, hidden_activation=\"relu\", output_activation=\"sigmoid\",\n",
    "        print_cost=True\n",
    "    )\n",
    "\n",
    "    # Évaluation du modèle entraîné\n",
    "    predictions, A_output = evaluate_model(X, Y, parameters, hidden_activation=\"relu\", output_activation=\"sigmoid\")\n",
    "\n",
    "    # Vérification des prédictions par rapport aux sorties attendues\n",
    "    if np.array_equal(predictions, expected_outputs):\n",
    "        print(f\"Test réussi pour {gate_type} ! Les prédictions sont correctes.\")\n",
    "    else:\n",
    "        print(f\"Test échoué pour {gate_type}.\")  # Affiche un message si le test échoue\n",
    "\n",
    "    # Affichage des prédictions binaires et des sorties attendues pour comparaison\n",
    "    print(\"Prédictions binaires:\\n\", predictions)\n",
    "    print(\"Sorties réelles attendues:\\n\", expected_outputs)\n",
    "\n",
    "    # Enregistrement des coûts d'entraînement pour ce type de porte logique\n",
    "    costs_dict[gate_type] = costs\n",
    "\n",
    "# Affichage des courbes de coût pour chaque porte logique\n",
    "plot_learning_curves(costs_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce graphique montre la courbe d'apprentissage pour trois portes logiques : AND, OR et XOR. L'axe des abscisses (x) représente les itérations, tandis que l'axe des ordonnées (y) représente le coût, qui diminue au fil de l'entraînement. Voici l'interprétation :\n",
    "\n",
    "- AND et OR : Les courbes pour les portes logiques AND et OR (bleu et orange) montrent une convergence rapide du coût vers zéro, indiquant que le modèle a appris à reproduire correctement les comportements des portes AND et OR après environ 1000 itérations.\n",
    "\n",
    "- XOR : La courbe verte représentant la porte XOR diminue beaucoup plus lentement. Elle atteint un coût proche de zéro vers 1500 itérations. Cela montre que la porte XOR est plus complexe à apprendre pour le modèle, car elle n'est pas linéairement séparable, nécessitant plus d'itérations pour converger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultats attendus pour les portes logiques ***AND***, ***OR*** et ***XOR*** avec ces hyperparamètres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nTest pour la porte logique: AND\\nCoût après l'itération 0: 0.69314737\\nCoût après l'itération 100: 0.56233466\\nCoût après l'itération 200: 0.56233394\\nCoût après l'itération 300: 0.56233296\\nCoût après l'itération 400: 0.56233139\\nCoût après l'itération 500: 0.56232810\\nCoût après l'itération 600: 0.56231922\\nCoût après l'itération 700: 0.56228264\\nCoût après l'itération 800: 0.56186654\\nCoût après l'itération 900: 0.42114591\\nCoût après l'itération 1000: 0.00431180\\nCoût après l'itération 1100: 0.00143322\\nCoût après l'itération 1200: 0.00079824\\nCoût après l'itération 1300: 0.00053632\\nCoût après l'itération 1400: 0.00039635\\nCoût après l'itération 1500: 0.00031112\\nCoût après l'itération 1600: 0.00025434\\nCoût après l'itération 1700: 0.00021404\\nCoût après l'itération 1800: 0.00018406\\nCoût après l'itération 1900: 0.00016096\\nCoût après l'itération 2000: 0.00014258\\nCoût après l'itération 2100: 0.00012785\\nCoût après l'itération 2200: 0.00011560\\nCoût après l'itération 2300: 0.00010539\\nSeuil de coût atteint à l'itération 2361 avec un coût de 0.00009993\\nTest réussi pour AND ! Les prédictions sont correctes.\\nPrédictions binaires:\\n [[0]\\n [0]\\n [0]\\n [1]]\\nSorties réelles attendues:\\n [[0]\\n [0]\\n [0]\\n [1]]\\n\\nTest pour la porte logique: OR\\nCoût après l'itération 0: 0.69314813\\nCoût après l'itération 100: 0.56233479\\nCoût après l'itération 200: 0.56233444\\nCoût après l'itération 300: 0.56233380\\nCoût après l'itération 400: 0.56233244\\nCoût après l'itération 500: 0.56232900\\nCoût après l'itération 600: 0.56231754\\nCoût après l'itération 700: 0.56225013\\nCoût après l'itération 800: 0.55963015\\nCoût après l'itération 900: 0.04217360\\nCoût après l'itération 1000: 0.00668038\\nCoût après l'itération 1100: 0.00285428\\nCoût après l'itération 1200: 0.00167373\\nCoût après l'itération 1300: 0.00114718\\nCoût après l'itération 1400: 0.00085505\\nCoût après l'itération 1500: 0.00067356\\nCoût après l'itération 1600: 0.00055086\\nCoût après l'itération 1700: 0.00046356\\nCoût après l'itération 1800: 0.00039812\\nCoût après l'itération 1900: 0.00034753\\nCoût après l'itération 2000: 0.00030748\\nCoût après l'itération 2100: 0.00027514\\nCoût après l'itération 2200: 0.00024844\\nCoût après l'itération 2300: 0.00022620\\nCoût après l'itération 2400: 0.00020729\\nCoût après l'itération 2500: 0.00019104\\nCoût après l'itération 2600: 0.00017699\\nCoût après l'itération 2700: 0.00016475\\nCoût après l'itération 2800: 0.00015393\\nCoût après l'itération 2900: 0.00014444\\nCoût après l'itération 3000: 0.00013588\\nCoût après l'itération 3100: 0.00012820\\nCoût après l'itération 3200: 0.00012131\\nCoût après l'itération 3300: 0.00011509\\nCoût après l'itération 3400: 0.00010939\\nCoût après l'itération 3500: 0.00010419\\nSeuil de coût atteint à l'itération 3589 avec un coût de 0.00009998\\nTest réussi pour OR ! Les prédictions sont correctes.\\nPrédictions binaires:\\n [[0]\\n [1]\\n [1]\\n [1]]\\nSorties réelles attendues:\\n [[0]\\n [1]\\n [1]\\n [1]]\\n\\nTest pour la porte logique: XOR\\nCoût après l'itération 0: 0.69314713\\nCoût après l'itération 100: 0.69314680\\nCoût après l'itération 200: 0.69314655\\nCoût après l'itération 300: 0.69314626\\nCoût après l'itération 400: 0.69314587\\nCoût après l'itération 500: 0.69314527\\nCoût après l'itération 600: 0.69314431\\nCoût après l'itération 700: 0.69314265\\nCoût après l'itération 800: 0.69313954\\nCoût après l'itération 900: 0.69313379\\nCoût après l'itération 1000: 0.69311742\\nCoût après l'itération 1100: 0.69306163\\nCoût après l'itération 1200: 0.69270855\\nCoût après l'itération 1300: 0.67617415\\nCoût après l'itération 1400: 0.01054084\\nCoût après l'itération 1500: 0.00272544\\nCoût après l'itération 1600: 0.00144240\\nCoût après l'itération 1700: 0.00095179\\nCoût après l'itération 1800: 0.00069998\\nCoût après l'itération 1900: 0.00054735\\nCoût après l'itération 2000: 0.00044671\\nCoût après l'itération 2100: 0.00037559\\nCoût après l'itération 2200: 0.00032295\\nCoût après l'itération 2300: 0.00028241\\nCoût après l'itération 2400: 0.00025028\\nCoût après l'itération 2500: 0.00022445\\nCoût après l'itération 2600: 0.00020311\\nCoût après l'itération 2700: 0.00018531\\nCoût après l'itération 2800: 0.00017016\\nCoût après l'itération 2900: 0.00015718\\nCoût après l'itération 3000: 0.00014593\\nCoût après l'itération 3100: 0.00013606\\nCoût après l'itération 3200: 0.00012739\\nCoût après l'itération 3300: 0.00011968\\nCoût après l'itération 3400: 0.00011283\\nCoût après l'itération 3500: 0.00010663\\nCoût après l'itération 3600: 0.00010107\\nSeuil de coût atteint à l'itération 3621 avec un coût de 0.00009996\\nTest réussi pour XOR ! Les prédictions sont correctes.\\nPrédictions binaires:\\n [[0]\\n [1]\\n [1]\\n [0]]\\nSorties réelles attendues:\\n [[0]\\n [1]\\n [1]\\n [0]]\\n\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Test pour la porte logique: AND\n",
    "Coût après l'itération 0: 0.69314737\n",
    "Coût après l'itération 100: 0.56233466\n",
    "Coût après l'itération 200: 0.56233394\n",
    "Coût après l'itération 300: 0.56233296\n",
    "Coût après l'itération 400: 0.56233139\n",
    "Coût après l'itération 500: 0.56232810\n",
    "Coût après l'itération 600: 0.56231922\n",
    "Coût après l'itération 700: 0.56228264\n",
    "Coût après l'itération 800: 0.56186654\n",
    "Coût après l'itération 900: 0.42114591\n",
    "Coût après l'itération 1000: 0.00431180\n",
    "Coût après l'itération 1100: 0.00143322\n",
    "Coût après l'itération 1200: 0.00079824\n",
    "Coût après l'itération 1300: 0.00053632\n",
    "Coût après l'itération 1400: 0.00039635\n",
    "Coût après l'itération 1500: 0.00031112\n",
    "Coût après l'itération 1600: 0.00025434\n",
    "Coût après l'itération 1700: 0.00021404\n",
    "Coût après l'itération 1800: 0.00018406\n",
    "Coût après l'itération 1900: 0.00016096\n",
    "Coût après l'itération 2000: 0.00014258\n",
    "Coût après l'itération 2100: 0.00012785\n",
    "Coût après l'itération 2200: 0.00011560\n",
    "Coût après l'itération 2300: 0.00010539\n",
    "Seuil de coût atteint à l'itération 2361 avec un coût de 0.00009993\n",
    "Test réussi pour AND ! Les prédictions sont correctes.\n",
    "Prédictions binaires:\n",
    " [[0]\n",
    " [0]\n",
    " [0]\n",
    " [1]]\n",
    "Sorties réelles attendues:\n",
    " [[0]\n",
    " [0]\n",
    " [0]\n",
    " [1]]\n",
    "\n",
    "Test pour la porte logique: OR\n",
    "Coût après l'itération 0: 0.69314813\n",
    "Coût après l'itération 100: 0.56233479\n",
    "Coût après l'itération 200: 0.56233444\n",
    "Coût après l'itération 300: 0.56233380\n",
    "Coût après l'itération 400: 0.56233244\n",
    "Coût après l'itération 500: 0.56232900\n",
    "Coût après l'itération 600: 0.56231754\n",
    "Coût après l'itération 700: 0.56225013\n",
    "Coût après l'itération 800: 0.55963015\n",
    "Coût après l'itération 900: 0.04217360\n",
    "Coût après l'itération 1000: 0.00668038\n",
    "Coût après l'itération 1100: 0.00285428\n",
    "Coût après l'itération 1200: 0.00167373\n",
    "Coût après l'itération 1300: 0.00114718\n",
    "Coût après l'itération 1400: 0.00085505\n",
    "Coût après l'itération 1500: 0.00067356\n",
    "Coût après l'itération 1600: 0.00055086\n",
    "Coût après l'itération 1700: 0.00046356\n",
    "Coût après l'itération 1800: 0.00039812\n",
    "Coût après l'itération 1900: 0.00034753\n",
    "Coût après l'itération 2000: 0.00030748\n",
    "Coût après l'itération 2100: 0.00027514\n",
    "Coût après l'itération 2200: 0.00024844\n",
    "Coût après l'itération 2300: 0.00022620\n",
    "Coût après l'itération 2400: 0.00020729\n",
    "Coût après l'itération 2500: 0.00019104\n",
    "Coût après l'itération 2600: 0.00017699\n",
    "Coût après l'itération 2700: 0.00016475\n",
    "Coût après l'itération 2800: 0.00015393\n",
    "Coût après l'itération 2900: 0.00014444\n",
    "Coût après l'itération 3000: 0.00013588\n",
    "Coût après l'itération 3100: 0.00012820\n",
    "Coût après l'itération 3200: 0.00012131\n",
    "Coût après l'itération 3300: 0.00011509\n",
    "Coût après l'itération 3400: 0.00010939\n",
    "Coût après l'itération 3500: 0.00010419\n",
    "Seuil de coût atteint à l'itération 3589 avec un coût de 0.00009998\n",
    "Test réussi pour OR ! Les prédictions sont correctes.\n",
    "Prédictions binaires:\n",
    " [[0]\n",
    " [1]\n",
    " [1]\n",
    " [1]]\n",
    "Sorties réelles attendues:\n",
    " [[0]\n",
    " [1]\n",
    " [1]\n",
    " [1]]\n",
    "\n",
    "Test pour la porte logique: XOR\n",
    "Coût après l'itération 0: 0.69314713\n",
    "Coût après l'itération 100: 0.69314680\n",
    "Coût après l'itération 200: 0.69314655\n",
    "Coût après l'itération 300: 0.69314626\n",
    "Coût après l'itération 400: 0.69314587\n",
    "Coût après l'itération 500: 0.69314527\n",
    "Coût après l'itération 600: 0.69314431\n",
    "Coût après l'itération 700: 0.69314265\n",
    "Coût après l'itération 800: 0.69313954\n",
    "Coût après l'itération 900: 0.69313379\n",
    "Coût après l'itération 1000: 0.69311742\n",
    "Coût après l'itération 1100: 0.69306163\n",
    "Coût après l'itération 1200: 0.69270855\n",
    "Coût après l'itération 1300: 0.67617415\n",
    "Coût après l'itération 1400: 0.01054084\n",
    "Coût après l'itération 1500: 0.00272544\n",
    "Coût après l'itération 1600: 0.00144240\n",
    "Coût après l'itération 1700: 0.00095179\n",
    "Coût après l'itération 1800: 0.00069998\n",
    "Coût après l'itération 1900: 0.00054735\n",
    "Coût après l'itération 2000: 0.00044671\n",
    "Coût après l'itération 2100: 0.00037559\n",
    "Coût après l'itération 2200: 0.00032295\n",
    "Coût après l'itération 2300: 0.00028241\n",
    "Coût après l'itération 2400: 0.00025028\n",
    "Coût après l'itération 2500: 0.00022445\n",
    "Coût après l'itération 2600: 0.00020311\n",
    "Coût après l'itération 2700: 0.00018531\n",
    "Coût après l'itération 2800: 0.00017016\n",
    "Coût après l'itération 2900: 0.00015718\n",
    "Coût après l'itération 3000: 0.00014593\n",
    "Coût après l'itération 3100: 0.00013606\n",
    "Coût après l'itération 3200: 0.00012739\n",
    "Coût après l'itération 3300: 0.00011968\n",
    "Coût après l'itération 3400: 0.00011283\n",
    "Coût après l'itération 3500: 0.00010663\n",
    "Coût après l'itération 3600: 0.00010107\n",
    "Seuil de coût atteint à l'itération 3621 avec un coût de 0.00009996\n",
    "Test réussi pour XOR ! Les prédictions sont correctes.\n",
    "Prédictions binaires:\n",
    " [[0]\n",
    " [1]\n",
    " [1]\n",
    " [0]]\n",
    "Sorties réelles attendues:\n",
    " [[0]\n",
    " [1]\n",
    " [1]\n",
    " [0]]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources :\n",
    "- Le cours de Deep Learning de M. Julien Velcin\n",
    "- Le cours de apprentissage supervisé par des réseaux de neurones de M. Dider Puzenat (M1)\n",
    "- Les TDS et leurs corrections de M. Dider Puzenat (M1)\n",
    "- Chatgpt pour la corrections des erreurs (les erreurs trop complexes)\n",
    "- Ce site la (https://pyimagesearch.com/2021/05/06/backpropagation-from-scratch-with-python/) pour la rétropropagation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
